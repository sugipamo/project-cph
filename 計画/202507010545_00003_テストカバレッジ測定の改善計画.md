# テストカバレッジ測定の改善計画

## 1. 現状分析

### 1.1 問題点
- **カバレッジツールの不在**: cargo-tarpaulinが未導入
- **可視性の欠如**: 実際のコードカバレッジが不明
- **品質管理の困難**: テストの網羅性を客観的に評価できない

### 1.2 影響
- コードの品質保証が主観的になりがち
- リファクタリング時のリスク評価が困難
- チーム全体でのテスト品質基準の共有が難しい

## 2. 改善計画

### 2.1 Phase 1: カバレッジツールの導入（1週間）

#### cargo-tarpaulinのセットアップ
```bash
# インストール
cargo install cargo-tarpaulin

# 基本実行
cargo tarpaulin

# HTMLレポート生成
cargo tarpaulin --out Html
```

#### GitHub Actionsへの統合
```yaml
name: Coverage
on: [push, pull_request]
jobs:
  coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          override: true
      - name: Run cargo-tarpaulin
        uses: actions-rs/tarpaulin@v0.1
        with:
          version: '0.27.0'
          args: '--ignore-tests'
      - name: Upload to codecov.io
        uses: codecov/codecov-action@v3
        with:
          token: ${{secrets.CODECOV_TOKEN}}
```

### 2.2 Phase 2: カバレッジ基準の設定（2週間）

#### 段階的な目標設定
1. **初期目標（1ヶ月）**: 60%
2. **中期目標（3ヶ月）**: 70%
3. **最終目標（6ヶ月）**: 85%

#### モジュール別の基準
```toml
# .tarpaulin.toml
[report]
out = ["Html", "Xml"]
output-dir = "target/coverage"

[coverage]
ignore-panics = true
ignore-tests = true

[[target]]
name = "domain"
min = 90  # ドメイン層は高カバレッジ必須

[[target]]
name = "infrastructure"
min = 80  # 副作用層も重要

[[target]]
name = "presentation"
min = 70  # UI層は相対的に低めでも可
```

### 2.3 Phase 3: 継続的改善プロセス（1ヶ月）

#### カバレッジレポートの活用
1. **PRごとのレビュー**
   - カバレッジの変化を自動コメント
   - 低下時は承認を必須化

2. **週次レポートの生成**
   ```rust
   // scripts/coverage_report.rs
   use std::fs;
   use serde_json::Value;
   
   fn generate_weekly_report() {
       let coverage_data = fs::read_to_string("coverage.json")
           .expect("Failed to read coverage data");
       let v: Value = serde_json::from_str(&coverage_data)
           .expect("Failed to parse JSON");
       
       // トレンド分析とレポート生成
   }
   ```

3. **ホットスポット分析**
   - 頻繁に変更されるが低カバレッジの箇所を特定
   - 優先的にテストを追加

## 3. 実装優先度マトリクス

| タスク | 影響度 | 実装コスト | 優先度 |
|--------|--------|------------|--------|
| tarpaulin導入 | 高 | 低 | 最高 |
| CI/CD統合 | 高 | 中 | 高 |
| カバレッジ基準設定 | 中 | 低 | 中 |
| レポート自動化 | 中 | 中 | 中 |
| ホットスポット分析 | 低 | 高 | 低 |

## 4. 期待される成果

- **品質の可視化**: カバレッジ率の数値化
- **リスクの低減**: 未テスト箇所の明確化
- **開発速度の向上**: 自信を持ったリファクタリング
- **チーム意識の向上**: 共通の品質基準

## 5. 注意事項とベストプラクティス

### 5.1 カバレッジの誤解を避ける
- 100%カバレッジ≠バグゼロ
- 質より量に陥らない
- 境界値テストの重要性

### 5.2 効果的なテスト戦略
```rust
// 悪い例：カバレッジのためだけのテスト
#[test]
fn test_trivial() {
    assert_eq!(add(1, 1), 2);
}

// 良い例：境界値と異常系を含む
#[test]
fn test_add_comprehensive() {
    assert_eq!(add(0, 0), 0);
    assert_eq!(add(i32::MAX, 1), i32::MIN); // オーバーフロー
    assert_eq!(add(-1, 1), 0);
}
```

## 6. 実装スケジュール

| 週 | タスク | 成果物 |
|----|--------|--------|
| 1 | tarpaulin導入とローカル実行 | カバレッジレポート |
| 2 | CI/CD統合 | 自動カバレッジ測定 |
| 3 | カバレッジ基準設定 | .tarpaulin.toml |
| 4 | レポート自動化 | 週次レポート |