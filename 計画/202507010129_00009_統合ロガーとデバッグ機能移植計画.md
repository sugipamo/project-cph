# 統合ロガーとデバッグ機能移植計画

## 現状の問題点

### 1. Pythonロギングシステムの複雑性
- operations/logging配下の多層的なロガー構造
- IntegratedLogger、FileLogger、ConsoleLoggerの複雑な統合
- 動的なログレベル切り替えとフィルタリング

### 2. デバッグ機能の分散
- デバッグモードの実装が各所に分散
- トレース情報の収集が不統一
- パフォーマンス計測機能の不足

## 対応方針

### Phase 1: ロギング基盤の構築（優先度: 高）

#### 1.1 ロガートレイトの定義
```rust
// src/domain/logging.rs
use async_trait::async_trait;
use chrono::{DateTime, Utc};
use std::fmt::Display;

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum LogLevel {
    Trace,
    Debug,
    Info,
    Warn,
    Error,
    Fatal,
}

#[derive(Debug, Clone)]
pub struct LogEntry {
    pub timestamp: DateTime<Utc>,
    pub level: LogLevel,
    pub message: String,
    pub module: String,
    pub file: Option<String>,
    pub line: Option<u32>,
    pub thread_id: String,
    pub context: HashMap<String, String>,
}

#[async_trait]
pub trait Logger: Send + Sync {
    async fn log(&self, entry: LogEntry) -> Result<()>;
    fn is_enabled(&self, level: LogLevel) -> bool;
    fn set_level(&mut self, level: LogLevel);
}

#[async_trait]
pub trait LogFilter: Send + Sync {
    async fn should_log(&self, entry: &LogEntry) -> bool;
}

pub trait LogFormatter: Send + Sync {
    fn format(&self, entry: &LogEntry) -> String;
}
```

#### 1.2 構造化ロギング実装
```rust
// src/infrastructure/logging/structured_logger.rs
use serde_json::json;
use tracing::{info, warn, error, debug, trace};

pub struct StructuredLogger {
    level: LogLevel,
    filters: Vec<Box<dyn LogFilter>>,
    sinks: Vec<Box<dyn LogSink>>,
}

#[async_trait]
pub trait LogSink: Send + Sync {
    async fn write(&self, entry: &LogEntry) -> Result<()>;
    async fn flush(&self) -> Result<()>;
}

impl StructuredLogger {
    pub fn new(level: LogLevel) -> Self {
        Self {
            level,
            filters: Vec::new(),
            sinks: Vec::new(),
        }
    }

    pub fn add_filter(mut self, filter: Box<dyn LogFilter>) -> Self {
        self.filters.push(filter);
        self
    }

    pub fn add_sink(mut self, sink: Box<dyn LogSink>) -> Self {
        self.sinks.push(sink);
        self
    }

    async fn should_log(&self, entry: &LogEntry) -> bool {
        if entry.level < self.level {
            return false;
        }

        for filter in &self.filters {
            if !filter.should_log(entry).await {
                return false;
            }
        }

        true
    }
}

#[async_trait]
impl Logger for StructuredLogger {
    async fn log(&self, entry: LogEntry) -> Result<()> {
        if !self.should_log(&entry).await {
            return Ok(());
        }

        // 並列でシンクに書き込み
        let futures: Vec<_> = self.sinks
            .iter()
            .map(|sink| sink.write(&entry))
            .collect();

        futures::future::try_join_all(futures).await?;
        Ok(())
    }

    fn is_enabled(&self, level: LogLevel) -> bool {
        level >= self.level
    }

    fn set_level(&mut self, level: LogLevel) {
        self.level = level;
    }
}
```

### Phase 2: ログシンクとフォーマッター（優先度: 高）

#### 2.1 ファイルログシンク
```rust
// src/infrastructure/logging/sinks/file_sink.rs
use tokio::fs::OpenOptions;
use tokio::io::AsyncWriteExt;
use tokio::sync::Mutex;

pub struct FileSink {
    path: PathBuf,
    formatter: Box<dyn LogFormatter>,
    file: Arc<Mutex<tokio::fs::File>>,
    rotation_config: Option<RotationConfig>,
}

#[derive(Debug, Clone)]
pub struct RotationConfig {
    pub max_size: u64,
    pub max_files: usize,
    pub compress: bool,
}

impl FileSink {
    pub async fn new(
        path: PathBuf,
        formatter: Box<dyn LogFormatter>,
        rotation_config: Option<RotationConfig>,
    ) -> Result<Self> {
        let file = OpenOptions::new()
            .create(true)
            .append(true)
            .open(&path)
            .await?;

        Ok(Self {
            path,
            formatter,
            file: Arc::new(Mutex::new(file)),
            rotation_config,
        })
    }

    async fn check_rotation(&self) -> Result<()> {
        if let Some(config) = &self.rotation_config {
            let metadata = tokio::fs::metadata(&self.path).await?;
            
            if metadata.len() > config.max_size {
                self.rotate_log().await?;
            }
        }
        Ok(())
    }

    async fn rotate_log(&self) -> Result<()> {
        let timestamp = Utc::now().format("%Y%m%d_%H%M%S");
        let rotated_path = self.path.with_file_name(
            format!("{}.{}", self.path.file_name().unwrap().to_str().unwrap(), timestamp)
        );

        tokio::fs::rename(&self.path, &rotated_path).await?;

        if let Some(config) = &self.rotation_config {
            if config.compress {
                self.compress_file(&rotated_path).await?;
            }
            self.cleanup_old_files(config.max_files).await?;
        }

        // 新しいファイルを開く
        let new_file = OpenOptions::new()
            .create(true)
            .append(true)
            .open(&self.path)
            .await?;

        let mut file = self.file.lock().await;
        *file = new_file;

        Ok(())
    }
}

#[async_trait]
impl LogSink for FileSink {
    async fn write(&self, entry: &LogEntry) -> Result<()> {
        self.check_rotation().await?;

        let formatted = self.formatter.format(entry);
        let mut file = self.file.lock().await;
        
        file.write_all(formatted.as_bytes()).await?;
        file.write_all(b"\n").await?;
        
        Ok(())
    }

    async fn flush(&self) -> Result<()> {
        let mut file = self.file.lock().await;
        file.flush().await?;
        Ok(())
    }
}
```

#### 2.2 コンソールログシンク
```rust
// src/infrastructure/logging/sinks/console_sink.rs
use colored::*;
use std::io::{self, Write};

pub struct ConsoleSink {
    formatter: Box<dyn LogFormatter>,
    use_stderr: bool,
    color_enabled: bool,
}

impl ConsoleSink {
    pub fn new(formatter: Box<dyn LogFormatter>, use_stderr: bool) -> Self {
        let color_enabled = atty::is(if use_stderr {
            atty::Stream::Stderr
        } else {
            atty::Stream::Stdout
        });

        Self {
            formatter,
            use_stderr,
            color_enabled,
        }
    }

    fn colorize_level(&self, level: LogLevel) -> String {
        if !self.color_enabled {
            return level.to_string();
        }

        match level {
            LogLevel::Trace => "TRACE".dimmed().to_string(),
            LogLevel::Debug => "DEBUG".blue().to_string(),
            LogLevel::Info => "INFO".green().to_string(),
            LogLevel::Warn => "WARN".yellow().to_string(),
            LogLevel::Error => "ERROR".red().to_string(),
            LogLevel::Fatal => "FATAL".red().bold().to_string(),
        }
    }
}

#[async_trait]
impl LogSink for ConsoleSink {
    async fn write(&self, entry: &LogEntry) -> Result<()> {
        let mut formatted = self.formatter.format(entry);
        
        if self.color_enabled {
            // レベルに応じて色付け
            formatted = formatted.replace(
                &entry.level.to_string(),
                &self.colorize_level(entry.level)
            );
        }

        if self.use_stderr {
            eprintln!("{}", formatted);
        } else {
            println!("{}", formatted);
        }

        Ok(())
    }

    async fn flush(&self) -> Result<()> {
        if self.use_stderr {
            io::stderr().flush()?;
        } else {
            io::stdout().flush()?;
        }
        Ok(())
    }
}
```

### Phase 3: デバッグ機能の統合（優先度: 高）

#### 3.1 デバッグトレーサー
```rust
// src/application/debug/tracer.rs
use std::sync::Arc;
use tokio::sync::RwLock;

pub struct DebugTracer {
    enabled: bool,
    traces: Arc<RwLock<Vec<TraceEntry>>>,
    max_traces: usize,
}

#[derive(Debug, Clone)]
pub struct TraceEntry {
    pub id: String,
    pub parent_id: Option<String>,
    pub operation: String,
    pub start_time: Instant,
    pub end_time: Option<Instant>,
    pub tags: HashMap<String, String>,
    pub events: Vec<TraceEvent>,
}

#[derive(Debug, Clone)]
pub struct TraceEvent {
    pub timestamp: Instant,
    pub message: String,
    pub data: HashMap<String, serde_json::Value>,
}

impl DebugTracer {
    pub fn new(enabled: bool, max_traces: usize) -> Self {
        Self {
            enabled,
            traces: Arc::new(RwLock::new(Vec::new())),
            max_traces,
        }
    }

    pub async fn start_trace(&self, operation: &str) -> TraceGuard {
        if !self.enabled {
            return TraceGuard::noop();
        }

        let id = Uuid::new_v4().to_string();
        let entry = TraceEntry {
            id: id.clone(),
            parent_id: None,
            operation: operation.to_string(),
            start_time: Instant::now(),
            end_time: None,
            tags: HashMap::new(),
            events: Vec::new(),
        };

        let mut traces = self.traces.write().await;
        traces.push(entry);

        // 最大数を超えたら古いものを削除
        if traces.len() > self.max_traces {
            traces.drain(0..traces.len() - self.max_traces);
        }

        TraceGuard {
            id,
            tracer: self.clone(),
        }
    }

    pub async fn add_event(&self, trace_id: &str, message: &str, data: HashMap<String, serde_json::Value>) {
        if !self.enabled {
            return;
        }

        let mut traces = self.traces.write().await;
        if let Some(trace) = traces.iter_mut().find(|t| t.id == trace_id) {
            trace.events.push(TraceEvent {
                timestamp: Instant::now(),
                message: message.to_string(),
                data,
            });
        }
    }

    pub async fn get_traces(&self) -> Vec<TraceEntry> {
        self.traces.read().await.clone()
    }
}

pub struct TraceGuard {
    id: String,
    tracer: DebugTracer,
}

impl Drop for TraceGuard {
    fn drop(&mut self) {
        let id = self.id.clone();
        let tracer = self.tracer.clone();
        
        tokio::spawn(async move {
            let mut traces = tracer.traces.write().await;
            if let Some(trace) = traces.iter_mut().find(|t| t.id == id) {
                trace.end_time = Some(Instant::now());
            }
        });
    }
}
```

#### 3.2 パフォーマンスプロファイラー
```rust
// src/application/debug/profiler.rs
pub struct PerformanceProfiler {
    enabled: bool,
    metrics: Arc<RwLock<HashMap<String, PerformanceMetric>>>,
}

#[derive(Debug, Clone)]
pub struct PerformanceMetric {
    pub operation: String,
    pub count: u64,
    pub total_duration: Duration,
    pub min_duration: Duration,
    pub max_duration: Duration,
    pub avg_duration: Duration,
    pub p50: Duration,
    pub p90: Duration,
    pub p99: Duration,
}

impl PerformanceProfiler {
    pub fn new(enabled: bool) -> Self {
        Self {
            enabled,
            metrics: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    pub async fn measure<F, T>(&self, operation: &str, f: F) -> Result<T>
    where
        F: Future<Output = Result<T>>,
    {
        if !self.enabled {
            return f.await;
        }

        let start = Instant::now();
        let result = f.await;
        let duration = start.elapsed();

        self.record_metric(operation, duration).await;
        result
    }

    async fn record_metric(&self, operation: &str, duration: Duration) {
        let mut metrics = self.metrics.write().await;
        
        let metric = metrics.entry(operation.to_string()).or_insert_with(|| {
            PerformanceMetric {
                operation: operation.to_string(),
                count: 0,
                total_duration: Duration::ZERO,
                min_duration: Duration::MAX,
                max_duration: Duration::ZERO,
                avg_duration: Duration::ZERO,
                p50: Duration::ZERO,
                p90: Duration::ZERO,
                p99: Duration::ZERO,
            }
        });

        metric.count += 1;
        metric.total_duration += duration;
        metric.min_duration = metric.min_duration.min(duration);
        metric.max_duration = metric.max_duration.max(duration);
        metric.avg_duration = metric.total_duration / metric.count as u32;
    }

    pub async fn get_report(&self) -> PerformanceReport {
        let metrics = self.metrics.read().await;
        
        PerformanceReport {
            metrics: metrics.values().cloned().collect(),
            total_operations: metrics.values().map(|m| m.count).sum(),
            generated_at: Utc::now(),
        }
    }
}
```

### Phase 4: 統合デバッグインターフェース（優先度: 中）

#### 4.1 デバッグコンテキスト
```rust
// src/application/debug/context.rs
pub struct DebugContext {
    pub tracer: Arc<DebugTracer>,
    pub profiler: Arc<PerformanceProfiler>,
    pub logger: Arc<dyn Logger>,
    pub breakpoints: Arc<RwLock<HashSet<String>>>,
    pub watch_expressions: Arc<RwLock<Vec<WatchExpression>>>,
}

#[derive(Debug, Clone)]
pub struct WatchExpression {
    pub id: String,
    pub expression: String,
    pub condition: Option<String>,
    pub log_message: Option<String>,
}

impl DebugContext {
    pub async fn set_breakpoint(&self, location: &str) -> Result<()> {
        let mut breakpoints = self.breakpoints.write().await;
        breakpoints.insert(location.to_string());
        
        self.logger.log(LogEntry {
            level: LogLevel::Debug,
            message: format!("Breakpoint set at {}", location),
            module: "debugger".to_string(),
            ..Default::default()
        }).await?;
        
        Ok(())
    }

    pub async fn check_breakpoint(&self, location: &str) -> bool {
        let breakpoints = self.breakpoints.read().await;
        breakpoints.contains(location)
    }

    pub async fn add_watch(&self, expression: &str, condition: Option<&str>) -> Result<String> {
        let id = Uuid::new_v4().to_string();
        let watch = WatchExpression {
            id: id.clone(),
            expression: expression.to_string(),
            condition: condition.map(|s| s.to_string()),
            log_message: None,
        };

        let mut watches = self.watch_expressions.write().await;
        watches.push(watch);

        Ok(id)
    }

    pub async fn evaluate_watches(&self, context: &HashMap<String, serde_json::Value>) -> Vec<WatchResult> {
        let watches = self.watch_expressions.read().await;
        let mut results = Vec::new();

        for watch in watches.iter() {
            let result = self.evaluate_expression(&watch.expression, context).await;
            
            if let Some(condition) = &watch.condition {
                let condition_result = self.evaluate_expression(condition, context).await;
                if !condition_result.unwrap_or(json!(false)).as_bool().unwrap_or(false) {
                    continue;
                }
            }

            results.push(WatchResult {
                watch_id: watch.id.clone(),
                expression: watch.expression.clone(),
                value: result,
                timestamp: Utc::now(),
            });
        }

        results
    }
}
```

### Phase 5: ログ分析と可視化（優先度: 低）

#### 5.1 ログアナライザー
```rust
// src/application/logging/analyzer.rs
pub struct LogAnalyzer {
    patterns: Vec<LogPattern>,
    aggregators: Vec<Box<dyn LogAggregator>>,
}

#[derive(Debug, Clone)]
pub struct LogPattern {
    pub name: String,
    pub regex: Regex,
    pub severity: LogLevel,
    pub tags: Vec<String>,
}

#[async_trait]
pub trait LogAggregator: Send + Sync {
    async fn aggregate(&mut self, entry: &LogEntry);
    async fn get_summary(&self) -> AggregationSummary;
}

pub struct ErrorRateAggregator {
    window: Duration,
    buckets: VecDeque<(DateTime<Utc>, u32)>,
    total_count: u64,
    error_count: u64,
}

impl LogAnalyzer {
    pub async fn analyze_logs(&mut self, entries: Vec<LogEntry>) -> AnalysisReport {
        let mut matched_patterns = HashMap::new();
        let mut severity_distribution = HashMap::new();

        for entry in &entries {
            // パターンマッチング
            for pattern in &self.patterns {
                if pattern.regex.is_match(&entry.message) {
                    *matched_patterns.entry(pattern.name.clone()).or_insert(0) += 1;
                }
            }

            // 重要度分布
            *severity_distribution.entry(entry.level).or_insert(0) += 1;

            // アグリゲーターに送信
            for aggregator in &mut self.aggregators {
                aggregator.aggregate(entry).await;
            }
        }

        // サマリー収集
        let mut aggregation_summaries = Vec::new();
        for aggregator in &self.aggregators {
            aggregation_summaries.push(aggregator.get_summary().await);
        }

        AnalysisReport {
            total_entries: entries.len(),
            time_range: self.get_time_range(&entries),
            matched_patterns,
            severity_distribution,
            aggregation_summaries,
            anomalies: self.detect_anomalies(&entries).await,
        }
    }

    async fn detect_anomalies(&self, entries: &[LogEntry]) -> Vec<Anomaly> {
        let mut anomalies = Vec::new();

        // エラー率の急増を検出
        let error_rate = self.calculate_error_rate(entries);
        if error_rate > 0.1 {  // 10%以上
            anomalies.push(Anomaly {
                severity: AnomalySeverity::High,
                description: format!("High error rate detected: {:.2}%", error_rate * 100.0),
                affected_modules: self.get_affected_modules(entries, LogLevel::Error),
            });
        }

        // 同じエラーの繰り返しを検出
        let repeated_errors = self.find_repeated_messages(entries, LogLevel::Error, 5);
        for (message, count) in repeated_errors {
            anomalies.push(Anomaly {
                severity: AnomalySeverity::Medium,
                description: format!("Error repeated {} times: {}", count, message),
                affected_modules: vec![],
            });
        }

        anomalies
    }
}
```

## 実装上の考慮事項

### 1. パフォーマンス最適化
- 非同期ログ書き込み
- バッファリングとバッチ処理
- 構造化ログの効率的な処理
- メモリ使用量の制限

### 2. 信頼性の確保
- ログ喪失の防止
- クラッシュ時の復旧
- ディスク容量管理
- バックプレッシャー処理

### 3. セキュリティ
- 機密情報のマスキング
- ログインジェクション防止
- アクセス制御
- 監査ログの保護

## 期待される効果

1. **観測可能性の向上**
   - 詳細なトレース情報
   - パフォーマンスメトリクス
   - エラーの早期発見

2. **デバッグ効率の向上**
   - 統合されたデバッグツール
   - リアルタイムモニタリング
   - 問題の迅速な特定

3. **運用性の向上**
   - ログ分析の自動化
   - アラートの適切な設定
   - トラブルシューティングの簡素化

## リスクと対策

### リスク
- パフォーマンスへの影響
- ストレージ容量の圧迫
- ログの複雑性増加

### 対策
- 適切なログレベル設定
- ログローテーション
- サンプリングの実装
- 効率的なフォーマット

## 実装優先順位

1. **即座に実装すべき項目**
   - 基本的なロガートレイト
   - ファイル・コンソール出力
   - 構造化ログサポート

2. **短期的に実装すべき項目**
   - デバッグトレーサー
   - パフォーマンスプロファイラー
   - ログローテーション

3. **中長期的に検討する項目**
   - ログ分析機能
   - 可視化ツール
   - 分散トレーシング