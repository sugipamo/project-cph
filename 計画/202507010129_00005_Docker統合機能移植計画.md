# Docker統合機能移植計画

## 現状の問題点

### 1. PythonのDocker機能の複雑性
- infrastructure/drivers/docker/docker_driver.pyの肥大化
- 動的型システムによるDocker API操作の不安定性
- エラーハンドリングの不十分さ

### 2. Rustプロジェクトとの不整合
- 現在のRustプロジェクトにDocker統合機能が欠如
- bollard crateの活用不足
- コンテナライフサイクル管理の欠如

## 対応方針

### Phase 1: Docker基盤の構築（優先度: 高）

#### 1.1 Dockerクライアントの抽象化
```rust
// src/infrastructure/docker/client.rs
use bollard::{Docker, API_DEFAULT_VERSION};
use bollard::errors::Error as BollardError;
use async_trait::async_trait;

#[async_trait]
pub trait DockerClient: Send + Sync {
    async fn info(&self) -> Result<SystemInfo>;
    async fn version(&self) -> Result<Version>;
    async fn ping(&self) -> Result<()>;
}

pub struct BollardDockerClient {
    client: Docker,
}

impl BollardDockerClient {
    pub async fn new() -> Result<Self> {
        let client = Docker::connect_with_local_defaults()?;
        Ok(Self { client })
    }

    pub async fn from_env() -> Result<Self> {
        let client = Docker::connect_with_socket_defaults()?;
        Ok(Self { client })
    }

    pub async fn with_url(url: &str) -> Result<Self> {
        let client = Docker::connect_with_http(
            url,
            120,
            API_DEFAULT_VERSION,
        )?;
        Ok(Self { client })
    }
}

#[async_trait]
impl DockerClient for BollardDockerClient {
    async fn info(&self) -> Result<SystemInfo> {
        self.client.info().await
            .map_err(|e| DockerError::ClientError(e.to_string()))
    }

    async fn version(&self) -> Result<Version> {
        self.client.version().await
            .map_err(|e| DockerError::ClientError(e.to_string()))
    }

    async fn ping(&self) -> Result<()> {
        self.client.ping().await
            .map_err(|e| DockerError::ClientError(e.to_string()))
    }
}
```

#### 1.2 コンテナ管理
```rust
// src/application/docker/container_manager.rs
use bollard::container::{
    Config, CreateContainerOptions, StartContainerOptions,
    StopContainerOptions, RemoveContainerOptions, LogsOptions,
};
use futures_util::stream::StreamExt;

pub struct ContainerManager {
    client: Arc<dyn DockerClient>,
    config: ContainerConfig,
}

#[derive(Debug, Clone)]
pub struct ContainerConfig {
    pub image: String,
    pub command: Vec<String>,
    pub env: HashMap<String, String>,
    pub volumes: Vec<VolumeMount>,
    pub working_dir: Option<String>,
    pub memory_limit: Option<i64>,
    pub cpu_limit: Option<f64>,
    pub timeout: Duration,
}

#[derive(Debug, Clone)]
pub struct VolumeMount {
    pub host_path: String,
    pub container_path: String,
    pub read_only: bool,
}

impl ContainerManager {
    pub fn new(client: Arc<dyn DockerClient>, config: ContainerConfig) -> Self {
        Self { client, config }
    }

    pub async fn create_container(&self, name: &str) -> Result<String> {
        let config = Config {
            image: Some(self.config.image.clone()),
            cmd: Some(self.config.command.clone()),
            env: Some(self.format_env()),
            host_config: Some(self.build_host_config()),
            working_dir: self.config.working_dir.clone(),
            ..Default::default()
        };

        let options = CreateContainerOptions {
            name: name.to_string(),
        };

        let response = self.client
            .create_container(Some(options), config)
            .await?;
        
        Ok(response.id)
    }

    pub async fn start_container(&self, id: &str) -> Result<()> {
        self.client
            .start_container(id, None::<StartContainerOptions<String>>)
            .await?;
        Ok(())
    }

    pub async fn wait_for_container(&self, id: &str) -> Result<i64> {
        let mut stream = self.client.wait_container(id, None);
        
        if let Some(result) = stream.next().await {
            let wait_response = result?;
            Ok(wait_response.status_code)
        } else {
            Err(DockerError::ContainerWaitFailed)
        }
    }

    pub async fn get_logs(&self, id: &str) -> Result<(String, String)> {
        let options = LogsOptions {
            stdout: true,
            stderr: true,
            follow: false,
            ..Default::default()
        };

        let mut stream = self.client.logs(id, Some(options));
        let mut stdout = String::new();
        let mut stderr = String::new();

        while let Some(result) = stream.next().await {
            match result? {
                LogOutput::StdOut { message } => {
                    stdout.push_str(&String::from_utf8_lossy(&message));
                }
                LogOutput::StdErr { message } => {
                    stderr.push_str(&String::from_utf8_lossy(&message));
                }
                _ => {}
            }
        }

        Ok((stdout, stderr))
    }

    pub async fn stop_container(&self, id: &str) -> Result<()> {
        let options = StopContainerOptions {
            t: 10, // 10秒のグレースフルシャットダウン
        };

        self.client
            .stop_container(id, Some(options))
            .await?;
        Ok(())
    }

    pub async fn remove_container(&self, id: &str) -> Result<()> {
        let options = RemoveContainerOptions {
            force: true,
            v: true, // ボリュームも削除
            ..Default::default()
        };

        self.client
            .remove_container(id, Some(options))
            .await?;
        Ok(())
    }

    fn format_env(&self) -> Vec<String> {
        self.config.env
            .iter()
            .map(|(k, v)| format!("{}={}", k, v))
            .collect()
    }

    fn build_host_config(&self) -> HostConfig {
        HostConfig {
            binds: Some(self.format_volumes()),
            memory: self.config.memory_limit,
            nano_cpus: self.config.cpu_limit.map(|cpu| (cpu * 1e9) as i64),
            ..Default::default()
        }
    }

    fn format_volumes(&self) -> Vec<String> {
        self.config.volumes
            .iter()
            .map(|v| {
                if v.read_only {
                    format!("{}:{}:ro", v.host_path, v.container_path)
                } else {
                    format!("{}:{}", v.host_path, v.container_path)
                }
            })
            .collect()
    }
}
```

### Phase 2: イメージ管理（優先度: 高）

#### 2.1 イメージビルダー
```rust
// src/application/docker/image_builder.rs
use bollard::image::{BuildImageOptions, CreateImageOptions};
use tokio::io::AsyncRead;
use tar::Builder;

pub struct ImageBuilder {
    client: Arc<dyn DockerClient>,
}

#[derive(Debug, Clone)]
pub struct BuildConfig {
    pub dockerfile_path: String,
    pub context_path: String,
    pub tag: String,
    pub build_args: HashMap<String, String>,
    pub labels: HashMap<String, String>,
    pub no_cache: bool,
}

impl ImageBuilder {
    pub fn new(client: Arc<dyn DockerClient>) -> Self {
        Self { client }
    }

    pub async fn build_image(&self, config: BuildConfig) -> Result<String> {
        let context = self.create_build_context(&config.context_path).await?;
        
        let options = BuildImageOptions {
            dockerfile: config.dockerfile_path,
            t: config.tag.clone(),
            buildargs: config.build_args,
            labels: config.labels,
            nocache: config.no_cache,
            ..Default::default()
        };

        let mut stream = self.client.build_image(options, None, Some(context));
        let mut image_id = String::new();

        while let Some(result) = stream.next().await {
            let info = result?;
            
            if let Some(stream) = info.stream {
                println!("{}", stream);
            }
            
            if let Some(aux) = info.aux {
                if let Some(id) = aux.id {
                    image_id = id;
                }
            }
            
            if let Some(error) = info.error {
                return Err(DockerError::BuildError(error));
            }
        }

        Ok(image_id)
    }

    pub async fn pull_image(&self, image: &str) -> Result<()> {
        let options = CreateImageOptions {
            from_image: image,
            ..Default::default()
        };

        let mut stream = self.client.create_image(Some(options), None, None);

        while let Some(result) = stream.next().await {
            let info = result?;
            
            if let Some(status) = info.status {
                println!("{}", status);
            }
            
            if let Some(error) = info.error {
                return Err(DockerError::PullError(error));
            }
        }

        Ok(())
    }

    pub async fn image_exists(&self, image: &str) -> Result<bool> {
        match self.client.inspect_image(image).await {
            Ok(_) => Ok(true),
            Err(BollardError::DockerResponseServerError { status_code: 404, .. }) => Ok(false),
            Err(e) => Err(DockerError::ClientError(e.to_string())),
        }
    }

    async fn create_build_context(&self, context_path: &str) -> Result<Vec<u8>> {
        let mut tar_builder = Builder::new(Vec::new());
        
        // コンテキストディレクトリを再帰的にtarに追加
        self.add_directory_to_tar(&mut tar_builder, context_path, "")?;
        
        let tar_data = tar_builder.into_inner()?;
        Ok(tar_data)
    }

    fn add_directory_to_tar(
        &self,
        builder: &mut Builder<Vec<u8>>,
        base_path: &str,
        prefix: &str,
    ) -> Result<()> {
        let entries = std::fs::read_dir(base_path)?;
        
        for entry in entries {
            let entry = entry?;
            let path = entry.path();
            let name = entry.file_name();
            let tar_path = if prefix.is_empty() {
                name.to_string_lossy().to_string()
            } else {
                format!("{}/{}", prefix, name.to_string_lossy())
            };
            
            if path.is_dir() {
                self.add_directory_to_tar(builder, &path.to_string_lossy(), &tar_path)?;
            } else {
                let mut file = std::fs::File::open(&path)?;
                builder.append_file(&tar_path, &mut file)?;
            }
        }
        
        Ok(())
    }
}
```

### Phase 3: 実行環境管理（優先度: 中）

#### 3.1 Docker Compose風の環境管理
```rust
// src/application/docker/environment_manager.rs
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DockerEnvironment {
    pub name: String,
    pub services: HashMap<String, ServiceConfig>,
    pub networks: HashMap<String, NetworkConfig>,
    pub volumes: HashMap<String, VolumeConfig>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ServiceConfig {
    pub image: String,
    pub build: Option<BuildContext>,
    pub command: Option<Vec<String>>,
    pub environment: HashMap<String, String>,
    pub ports: Vec<PortMapping>,
    pub volumes: Vec<String>,
    pub depends_on: Vec<String>,
    pub networks: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BuildContext {
    pub context: String,
    pub dockerfile: Option<String>,
    pub args: HashMap<String, String>,
}

pub struct EnvironmentManager {
    client: Arc<dyn DockerClient>,
    environments: HashMap<String, DockerEnvironment>,
}

impl EnvironmentManager {
    pub fn new(client: Arc<dyn DockerClient>) -> Self {
        Self {
            client,
            environments: HashMap::new(),
        }
    }

    pub async fn load_environment(&mut self, path: &str) -> Result<String> {
        let content = tokio::fs::read_to_string(path).await?;
        let env: DockerEnvironment = serde_yaml::from_str(&content)?;
        let name = env.name.clone();
        
        self.environments.insert(name.clone(), env);
        Ok(name)
    }

    pub async fn start_environment(&self, name: &str) -> Result<()> {
        let env = self.environments.get(name)
            .ok_or_else(|| DockerError::EnvironmentNotFound(name.to_string()))?;
        
        // ネットワークを作成
        for (net_name, net_config) in &env.networks {
            self.create_network(net_name, net_config).await?;
        }
        
        // ボリュームを作成
        for (vol_name, vol_config) in &env.volumes {
            self.create_volume(vol_name, vol_config).await?;
        }
        
        // 依存関係順にサービスを起動
        let sorted_services = self.topological_sort(&env.services)?;
        
        for service_name in sorted_services {
            let service = &env.services[&service_name];
            self.start_service(&service_name, service, &env.name).await?;
        }
        
        Ok(())
    }

    pub async fn stop_environment(&self, name: &str) -> Result<()> {
        let env = self.environments.get(name)
            .ok_or_else(|| DockerError::EnvironmentNotFound(name.to_string()))?;
        
        // サービスを逆順で停止
        let sorted_services = self.topological_sort(&env.services)?;
        
        for service_name in sorted_services.into_iter().rev() {
            self.stop_service(&service_name, &env.name).await?;
        }
        
        Ok(())
    }

    async fn start_service(
        &self,
        name: &str,
        config: &ServiceConfig,
        env_name: &str,
    ) -> Result<()> {
        // イメージのビルドまたはプル
        if let Some(build) = &config.build {
            let builder = ImageBuilder::new(self.client.clone());
            let build_config = BuildConfig {
                dockerfile_path: build.dockerfile.clone()
                    .unwrap_or_else(|| "Dockerfile".to_string()),
                context_path: build.context.clone(),
                tag: config.image.clone(),
                build_args: build.args.clone(),
                labels: HashMap::new(),
                no_cache: false,
            };
            builder.build_image(build_config).await?;
        } else {
            let builder = ImageBuilder::new(self.client.clone());
            if !builder.image_exists(&config.image).await? {
                builder.pull_image(&config.image).await?;
            }
        }
        
        // コンテナの作成と起動
        let container_config = ContainerConfig {
            image: config.image.clone(),
            command: config.command.clone().unwrap_or_default(),
            env: config.environment.clone(),
            volumes: self.parse_volumes(&config.volumes),
            working_dir: None,
            memory_limit: None,
            cpu_limit: None,
            timeout: Duration::from_secs(300),
        };
        
        let manager = ContainerManager::new(self.client.clone(), container_config);
        let container_name = format!("{}_{}", env_name, name);
        
        let container_id = manager.create_container(&container_name).await?;
        manager.start_container(&container_id).await?;
        
        Ok(())
    }

    fn topological_sort(&self, services: &HashMap<String, ServiceConfig>) -> Result<Vec<String>> {
        // トポロジカルソートの実装
        let mut graph: HashMap<String, Vec<String>> = HashMap::new();
        let mut in_degree: HashMap<String, usize> = HashMap::new();
        
        // グラフを構築
        for (name, service) in services {
            graph.insert(name.clone(), service.depends_on.clone());
            in_degree.insert(name.clone(), 0);
        }
        
        // 入次数を計算
        for deps in graph.values() {
            for dep in deps {
                *in_degree.get_mut(dep).unwrap() += 1;
            }
        }
        
        // トポロジカルソート
        let mut queue: VecDeque<String> = in_degree
            .iter()
            .filter(|(_, &degree)| degree == 0)
            .map(|(name, _)| name.clone())
            .collect();
        
        let mut sorted = Vec::new();
        
        while let Some(node) = queue.pop_front() {
            sorted.push(node.clone());
            
            if let Some(deps) = graph.get(&node) {
                for dep in deps {
                    let degree = in_degree.get_mut(dep).unwrap();
                    *degree -= 1;
                    if *degree == 0 {
                        queue.push_back(dep.clone());
                    }
                }
            }
        }
        
        if sorted.len() != services.len() {
            return Err(DockerError::CircularDependency);
        }
        
        Ok(sorted)
    }
}
```

### Phase 4: 監視とログ管理（優先度: 中）

#### 4.1 コンテナ監視
```rust
// src/application/docker/monitor.rs
use bollard::container::StatsOptions;

pub struct ContainerMonitor {
    client: Arc<dyn DockerClient>,
}

#[derive(Debug, Clone)]
pub struct ContainerStats {
    pub cpu_usage: f64,
    pub memory_usage: u64,
    pub memory_limit: u64,
    pub network_rx: u64,
    pub network_tx: u64,
    pub block_read: u64,
    pub block_write: u64,
}

impl ContainerMonitor {
    pub fn new(client: Arc<dyn DockerClient>) -> Self {
        Self { client }
    }

    pub async fn get_stats(&self, container_id: &str) -> Result<ContainerStats> {
        let options = StatsOptions {
            stream: false,
            one_shot: true,
        };
        
        let mut stream = self.client.stats(container_id, Some(options));
        
        if let Some(result) = stream.next().await {
            let stats = result?;
            Ok(self.parse_stats(stats))
        } else {
            Err(DockerError::StatsNotAvailable)
        }
    }

    pub async fn stream_logs(&self, container_id: &str) -> Result<impl Stream<Item = Result<String>>> {
        let options = LogsOptions {
            stdout: true,
            stderr: true,
            follow: true,
            timestamps: true,
            ..Default::default()
        };
        
        let stream = self.client.logs(container_id, Some(options));
        
        Ok(stream.map(|result| {
            result.map(|output| match output {
                LogOutput::StdOut { message } => String::from_utf8_lossy(&message).to_string(),
                LogOutput::StdErr { message } => String::from_utf8_lossy(&message).to_string(),
                _ => String::new(),
            })
            .map_err(|e| DockerError::LogStreamError(e.to_string()))
        }))
    }

    fn parse_stats(&self, stats: Stats) -> ContainerStats {
        let cpu_delta = stats.cpu_stats.cpu_usage.total_usage - stats.precpu_stats.cpu_usage.total_usage;
        let system_delta = stats.cpu_stats.system_cpu_usage.unwrap_or(0) - stats.precpu_stats.system_cpu_usage.unwrap_or(0);
        let cpu_usage = if system_delta > 0 {
            (cpu_delta as f64 / system_delta as f64) * 100.0
        } else {
            0.0
        };
        
        ContainerStats {
            cpu_usage,
            memory_usage: stats.memory_stats.usage.unwrap_or(0),
            memory_limit: stats.memory_stats.limit.unwrap_or(0),
            network_rx: stats.networks.values().map(|n| n.rx_bytes).sum(),
            network_tx: stats.networks.values().map(|n| n.tx_bytes).sum(),
            block_read: stats.blkio_stats.io_service_bytes_recursive
                .as_ref()
                .map(|io| io.iter().filter(|s| s.op == "Read").map(|s| s.value).sum())
                .unwrap_or(0),
            block_write: stats.blkio_stats.io_service_bytes_recursive
                .as_ref()
                .map(|io| io.iter().filter(|s| s.op == "Write").map(|s| s.value).sum())
                .unwrap_or(0),
        }
    }
}
```

### Phase 5: 統合とセキュリティ（優先度: 低）

#### 5.1 セキュリティ強化
```rust
// src/application/docker/security.rs
pub struct SecurityConfig {
    pub read_only_root: bool,
    pub no_new_privileges: bool,
    pub user: Option<String>,
    pub capabilities_add: Vec<String>,
    pub capabilities_drop: Vec<String>,
    pub seccomp_profile: Option<String>,
}

impl SecurityConfig {
    pub fn minimal() -> Self {
        Self {
            read_only_root: true,
            no_new_privileges: true,
            user: Some("nobody".to_string()),
            capabilities_add: vec![],
            capabilities_drop: vec!["ALL".to_string()],
            seccomp_profile: Some("default".to_string()),
        }
    }

    pub fn apply_to_host_config(&self, host_config: &mut HostConfig) {
        host_config.read_only_rootfs = Some(self.read_only_root);
        host_config.security_opt = Some(vec![
            "no-new-privileges".to_string(),
        ]);
        
        if let Some(user) = &self.user {
            host_config.user = Some(user.clone());
        }
        
        host_config.cap_add = Some(self.capabilities_add.clone());
        host_config.cap_drop = Some(self.capabilities_drop.clone());
    }
}
```

## 実装上の考慮事項

### 1. パフォーマンス最適化
- 非同期ストリーミングAPIの活用
- コネクションプーリング
- バックグラウンドタスクでの画像プル
- 並列コンテナ操作

### 2. エラーハンドリング
- 詳細なエラー型の定義
- リトライ機構の実装
- グレースフルシャットダウン
- タイムアウト処理

### 3. セキュリティ
- 最小権限の原則
- イメージスキャニング
- ネットワーク分離
- シークレット管理

## 期待される効果

1. **信頼性向上**
   - 型安全なDocker API操作
   - 詳細なエラーハンドリング
   - 予測可能な動作

2. **パフォーマンス向上**
   - 非同期処理による効率化
   - リソース使用の最適化
   - 並列実行のサポート

3. **保守性向上**
   - モジュール化された設計
   - テスタブルなコード
   - 明確なインターフェース

## リスクと対策

### リスク
- bollard APIの変更
- Docker Engine互換性
- 既存ワークフローへの影響

### 対策
- 抽象化レイヤーの提供
- バージョン固定とテスト
- 段階的な移行計画
- フォールバック機構

## 実装優先順位

1. **即座に実装すべき項目**
   - Dockerクライアントの基本実装
   - コンテナ作成・実行・削除
   - イメージのプル機能

2. **短期的に実装すべき項目**
   - イメージビルド機能
   - ログ取得機能
   - 基本的な監視機能

3. **中長期的に検討する項目**
   - 環境管理機能
   - 高度なセキュリティ機能
   - クラスタ対応