#!/usr/bin/env python3
"""
å¼·åŒ–ã•ã‚ŒãŸã‚¤ãƒ³ãƒãƒ¼ãƒˆé–¢ä¿‚åˆ†æãƒ„ãƒ¼ãƒ«
"""

import ast
import os
import re
from pathlib import Path
from collections import defaultdict, deque
from typing import Dict, List, Set, Tuple, Optional
import json

class EnhancedImportAnalyzer:
    def __init__(self, src_path: str):
        self.src_path = Path(src_path)
        self.modules: Dict[str, Dict] = {}
        self.import_graph: Dict[str, Set[str]] = defaultdict(set)
        self.reverse_import_graph: Dict[str, Set[str]] = defaultdict(set)
        self.file_to_module: Dict[str, str] = {}
        
    def get_module_path(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        relative_path = file_path.relative_to(self.src_path)
        if relative_path.name == "__init__.py":
            if str(relative_path.parent) == ".":
                return "src"
            return "src." + str(relative_path.parent).replace("/", ".")
        else:
            module_path = str(relative_path.with_suffix("")).replace("/", ".")
            return "src." + module_path
    
    def normalize_import(self, import_name: str, current_module: str) -> str:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆåã‚’æ­£è¦åŒ–"""
        if import_name.startswith("."):
            # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            parts = current_module.split(".")
            if import_name.startswith(".."):
                level = len(import_name) - len(import_name.lstrip("."))
                base_parts = parts[:-level] if level < len(parts) else []
                remaining = import_name[level:]
                if remaining:
                    return ".".join(base_parts + [remaining])
                else:
                    return ".".join(base_parts)
            else:
                remaining = import_name[1:]
                if remaining:
                    return ".".join(parts[:-1] + [remaining])
                else:
                    return ".".join(parts[:-1])
        else:
            return import_name
    
    def extract_imports_from_file(self, file_path: Path) -> Tuple[List[str], List[Tuple[str, List[str]]]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’æŠ½å‡ºã—ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’è¿”ã™"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            imports = []
            from_imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.append(node.module)
                        # from X import Y ã®å½¢å¼ã‚‚è¨˜éŒ²
                        imported_names = [alias.name for alias in node.names]
                        from_imports.append((node.module, imported_names))
                        
            return imports, from_imports
        except Exception as e:
            print(f"Error parsing {file_path}: {e}")
            return [], []
    
    def analyze_all_files(self):
        """å…¨ã¦ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""
        print("Analyzing all Python files...")
        
        for py_file in self.src_path.rglob("*.py"):
            module_path = self.get_module_path(py_file)
            self.file_to_module[str(py_file)] = module_path
            
            imports, from_imports = self.extract_imports_from_file(py_file)
            
            self.modules[module_path] = {
                "file_path": str(py_file),
                "raw_imports": imports,
                "from_imports": from_imports,
                "normalized_imports": [],
                "internal_imports": [],
                "external_imports": []
            }
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ­£è¦åŒ–ã—ã€å†…éƒ¨/å¤–éƒ¨ã‚’åˆ†é¡
            for imp in imports:
                normalized = self.normalize_import(imp, module_path)
                self.modules[module_path]["normalized_imports"].append(normalized)
                
                # å†…éƒ¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‹å¤–éƒ¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‹ã‚’åˆ¤å®š
                if normalized.startswith("src."):
                    self.modules[module_path]["internal_imports"].append(normalized)
                    # ã‚°ãƒ©ãƒ•ã«è¿½åŠ 
                    self.import_graph[module_path].add(normalized)
                    self.reverse_import_graph[normalized].add(module_path)
                else:
                    self.modules[module_path]["external_imports"].append(normalized)
        
        print(f"Found {len(self.modules)} modules")
    
    def find_circular_dependencies(self) -> List[List[str]]:
        """DFSã‚’ä½¿ã£ã¦å¾ªç’°ä¾å­˜ã‚’æ¤œå‡º"""
        def dfs(node, path, visited, rec_stack):
            visited.add(node)
            rec_stack.add(node)
            
            for neighbor in self.import_graph.get(node, []):
                if neighbor in self.modules:  # å­˜åœ¨ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿
                    if neighbor in rec_stack:
                        # å¾ªç’°ã‚’ç™ºè¦‹
                        cycle_start_idx = path.index(neighbor) if neighbor in path else len(path)
                        cycle = path[cycle_start_idx:] + [neighbor]
                        if len(cycle) > 1:  # è‡ªå·±å‚ç…§ä»¥å¤–
                            cycles.append(cycle)
                    elif neighbor not in visited:
                        dfs(neighbor, path + [neighbor], visited, rec_stack)
            
            rec_stack.remove(node)
        
        cycles = []
        visited = set()
        
        for node in self.modules:
            if node not in visited:
                dfs(node, [node], visited, set())
        
        # é‡è¤‡ã™ã‚‹å¾ªç’°ã‚’é™¤å»
        unique_cycles = []
        for cycle in cycles:
            # æ­£è¦åŒ–ï¼ˆæœ€å°è¦ç´ ã‹ã‚‰é–‹å§‹ï¼‰
            min_idx = cycle.index(min(cycle))
            normalized_cycle = cycle[min_idx:] + cycle[:min_idx]
            if normalized_cycle not in unique_cycles:
                unique_cycles.append(normalized_cycle)
        
        return unique_cycles
    
    def calculate_layers_with_cycles(self) -> Dict[str, int]:
        """å¾ªç’°ä¾å­˜ã‚’è€ƒæ…®ã—ãŸãƒ¬ã‚¤ãƒ¤ãƒ¼è¨ˆç®—"""
        layers = {}
        processed = set()
        
        # ã¾ãšå¾ªç’°ä¾å­˜ã‚’è­˜åˆ¥
        cycles = self.find_circular_dependencies()
        cycle_members = set()
        for cycle in cycles:
            cycle_members.update(cycle)
        
        # å¾ªç’°ã—ã¦ã„ãªã„ãƒãƒ¼ãƒ‰ã‹ã‚‰å‡¦ç†
        queue = deque()
        in_degree = defaultdict(int)
        
        # å…¥æ¬¡æ•°ã‚’è¨ˆç®—ï¼ˆå¾ªç’°ãƒ¡ãƒ³ãƒãƒ¼ã¯é™¤å¤–ã—ã¦ï¼‰
        for node in self.modules:
            if node not in cycle_members:
                in_degree[node] = 0
                for dep in self.import_graph.get(node, []):
                    if dep in self.modules and dep not in cycle_members:
                        in_degree[node] += 1
        
        # å…¥æ¬¡æ•°0ã®ãƒãƒ¼ãƒ‰ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        for node in self.modules:
            if node not in cycle_members and in_degree[node] == 0:
                queue.append(node)
                layers[node] = 0
        
        # ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ã‚½ãƒ¼ãƒˆ
        max_layer = 0
        while queue:
            current = queue.popleft()
            processed.add(current)
            
            for neighbor in self.import_graph.get(current, []):
                if neighbor in self.modules and neighbor not in cycle_members:
                    in_degree[neighbor] -= 1
                    if in_degree[neighbor] == 0:
                        layers[neighbor] = layers[current] + 1
                        max_layer = max(max_layer, layers[neighbor])
                        queue.append(neighbor)
        
        # å¾ªç’°ãƒ¡ãƒ³ãƒãƒ¼ã«ã¯ç‰¹åˆ¥ãªãƒãƒ¼ã‚«ãƒ¼ã‚’ä»˜ä¸
        for node in cycle_members:
            layers[node] = -1
        
        return layers
    
    def analyze_focus_modules(self, focus_modules: List[str]) -> Dict:
        """ç‰¹å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤ã®è©³ç´°åˆ†æ"""
        layers = self.calculate_layers_with_cycles()
        analysis = {}
        
        for focus in focus_modules:
            analysis[focus] = {
                "modules": [],
                "layer_distribution": defaultdict(int),
                "circular_modules": [],
                "dependencies": set(),
                "dependents": set()
            }
            
            for module_name in self.modules:
                if module_name.startswith(f"src.{focus}"):
                    layer = layers.get(module_name, -1)
                    analysis[focus]["layer_distribution"][layer] += 1
                    
                    if layer == -1:
                        analysis[focus]["circular_modules"].append(module_name)
                    
                    module_info = {
                        "name": module_name,
                        "layer": layer,
                        "imports": self.modules[module_name]["internal_imports"],
                        "imported_by": list(self.reverse_import_graph.get(module_name, [])),
                        "file_path": self.modules[module_name]["file_path"]
                    }
                    analysis[focus]["modules"].append(module_info)
                    
                    # ä¾å­˜é–¢ä¿‚ã‚’é›†è¨ˆ
                    for imp in self.modules[module_name]["internal_imports"]:
                        if not imp.startswith(f"src.{focus}"):
                            analysis[focus]["dependencies"].add(imp)
                    
                    for imp_by in self.reverse_import_graph.get(module_name, []):
                        if not imp_by.startswith(f"src.{focus}"):
                            analysis[focus]["dependents"].add(imp_by)
            
            # setã‚’listã«å¤‰æ›ï¼ˆJSON serializableï¼‰
            analysis[focus]["dependencies"] = list(analysis[focus]["dependencies"])
            analysis[focus]["dependents"] = list(analysis[focus]["dependents"])
        
        return analysis
    
    def generate_detailed_report(self) -> Dict:
        """è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        circular_deps = self.find_circular_dependencies()
        layers = self.calculate_layers_with_cycles()
        
        focus_modules = [
            "shared.utils",
            "application.formatters", 
            "context",
            "infrastructure"
        ]
        
        focus_analysis = self.analyze_focus_modules(focus_modules)
        
        # å±¤åˆ¥çµ±è¨ˆ
        layer_stats = defaultdict(int)
        for layer in layers.values():
            layer_stats[layer] += 1
        
        return {
            "summary": {
                "total_modules": len(self.modules),
                "circular_dependencies": len(circular_deps),
                "modules_in_cycles": len([m for m in self.modules if layers.get(m) == -1]),
                "max_layer": max([l for l in layers.values() if l >= 0], default=0),
                "layer_distribution": dict(layer_stats)
            },
            "circular_dependencies": circular_deps,
            "layers": layers,
            "focus_analysis": focus_analysis,
            "problem_areas": self.identify_problem_areas(circular_deps, layers)
        }
    
    def identify_problem_areas(self, circular_deps: List[List[str]], layers: Dict[str, int]) -> Dict:
        """å•é¡Œé ˜åŸŸã‚’ç‰¹å®š"""
        problems = {
            "architectural_violations": [],
            "high_coupling_modules": [],
            "layer_violations": []
        }
        
        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é•åã‚’æ¤œå‡º
        for module_name, module_data in self.modules.items():
            # shared.utilsãŒapplicationã‚’å‚ç…§ã—ã¦ã„ã‚‹
            if module_name.startswith("src.shared.utils"):
                for imp in module_data["internal_imports"]:
                    if imp.startswith("src.application"):
                        problems["architectural_violations"].append({
                            "violator": module_name,
                            "violation": f"shared.utils module importing from application layer",
                            "imported": imp
                        })
            
            # contextãŒapplicationã‚’å‚ç…§ã—ã¦ã„ã‚‹
            if module_name.startswith("src.context"):
                for imp in module_data["internal_imports"]:
                    if imp.startswith("src.application"):
                        problems["architectural_violations"].append({
                            "violator": module_name,
                            "violation": f"context module importing from application layer",
                            "imported": imp
                        })
        
        # é«˜çµåˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ¤œå‡º
        for module_name in self.modules:
            import_count = len(self.modules[module_name]["internal_imports"])
            imported_by_count = len(self.reverse_import_graph.get(module_name, []))
            
            if import_count > 10 or imported_by_count > 10:
                problems["high_coupling_modules"].append({
                    "module": module_name,
                    "imports": import_count,
                    "imported_by": imported_by_count
                })
        
        return problems

def main():
    analyzer = EnhancedImportAnalyzer("/home/cphelper/project-cph/src")
    analyzer.analyze_all_files()
    report = analyzer.generate_detailed_report()
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open("/home/cphelper/project-cph/enhanced_import_analysis.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # ä¸»è¦ãªçµæœã‚’è¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ” å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*80)
    
    print(f"\nğŸ“Š æ¦‚è¦:")
    print(f"  ğŸ“¦ ç·ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°: {report['summary']['total_modules']}")
    print(f"  ğŸ”„ å¾ªç’°ä¾å­˜æ•°: {report['summary']['circular_dependencies']}")
    print(f"  âš ï¸  å¾ªç’°ã«å«ã¾ã‚Œã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {report['summary']['modules_in_cycles']}")
    print(f"  ğŸ“Š æœ€å¤§ãƒ¬ã‚¤ãƒ¤ãƒ¼: {report['summary']['max_layer']}")
    print(f"  ğŸ“ˆ ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†å¸ƒ: {report['summary']['layer_distribution']}")
    
    if report['circular_dependencies']:
        print(f"\nğŸ”„ å¾ªç’°ä¾å­˜ ({len(report['circular_dependencies'])} å€‹):")
        for i, cycle in enumerate(report['circular_dependencies']):
            print(f"  {i+1}. {' â†’ '.join(cycle)} â†’ {cycle[0]}")
    
    print(f"\nâš ï¸  å•é¡Œé ˜åŸŸ:")
    problems = report['problem_areas']
    
    if problems['architectural_violations']:
        print(f"  ğŸ—ï¸  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é•å ({len(problems['architectural_violations'])} å€‹):")
        for violation in problems['architectural_violations'][:5]:
            print(f"    â€¢ {violation['violator']} â†’ {violation['imported']}")
            print(f"      ç†ç”±: {violation['violation']}")
    
    if problems['high_coupling_modules']:
        print(f"  ğŸ”— é«˜çµåˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ({len(problems['high_coupling_modules'])} å€‹):")
        for module in sorted(problems['high_coupling_modules'], 
                           key=lambda x: x['imports'] + x['imported_by'], reverse=True)[:5]:
            print(f"    â€¢ {module['module']}: {module['imports']} ã‚¤ãƒ³ãƒãƒ¼ãƒˆ, {module['imported_by']} è¢«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    
    print(f"\nğŸ“‹ æ³¨ç›®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤ã®åˆ†æ:")
    for focus_name, focus_data in report['focus_analysis'].items():
        print(f"\n  ğŸ“‚ {focus_name}:")
        print(f"    ğŸ“¦ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°: {len(focus_data['modules'])}")
        print(f"    ğŸ“Š ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†å¸ƒ: {dict(focus_data['layer_distribution'])}")
        
        if focus_data['circular_modules']:
            print(f"    ğŸ”„ å¾ªç’°ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {len(focus_data['circular_modules'])}")
            for circ_mod in focus_data['circular_modules'][:3]:
                print(f"      â€¢ {circ_mod}")
        
        if focus_data['dependencies']:
            print(f"    â¬‡ï¸  å¤–éƒ¨ä¾å­˜: {len(focus_data['dependencies'])} å€‹")
            for dep in sorted(list(focus_data['dependencies']))[:3]:
                print(f"      â€¢ {dep}")
        
        if focus_data['dependents']:
            print(f"    â¬†ï¸  è¢«ä¾å­˜: {len(focus_data['dependents'])} å€‹")
            for dep in sorted(list(focus_data['dependents']))[:3]:
                print(f"      â€¢ {dep}")

if __name__ == "__main__":
    main()