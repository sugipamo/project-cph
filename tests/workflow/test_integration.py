"""
大規模ワークフローの統合テスト
"""
import pytest
import tempfile
import shutil
from pathlib import Path
from unittest.mock import Mock, patch
from src.env.workflow.graph_based_workflow_builder import GraphBasedWorkflowBuilder
from src.env.workflow.request_execution_graph import RequestExecutionGraph
from src.env.workflow.graph_to_composite_adapter import GraphToCompositeAdapter
from src.operations.di_container import DIContainer
from src.operations.result.result import OperationResult
from src.env.step_generation.step import Step, StepType, StepContext


class TestIntegration:
    """大規模ワークフローの統合テストクラス"""
    
    @pytest.fixture\n    def temp_dir(self):\n        \"\"\"テスト用の一時ディレクトリ\"\"\"\n        temp_path = tempfile.mkdtemp()\n        yield temp_path\n        shutil.rmtree(temp_path, ignore_errors=True)\n    \n    @pytest.fixture\n    def mock_controller(self):\n        \"\"\"モックコントローラー\"\"\"\n        controller = Mock()\n        controller.env_context = Mock()\n        controller.env_context.contest_name = \"integration_test\"\n        controller.env_context.problem_name = \"large_workflow\"\n        controller.env_context.language = \"python\"\n        controller.env_context.env_type = \"local\"\n        controller.env_context.command_type = \"run\"\n        return controller\n    \n    @pytest.fixture\n    def mock_operations(self):\n        \"\"\"モックDIコンテナ\"\"\"\n        operations = Mock(spec=DIContainer)\n        return operations\n    \n    def create_large_workflow_steps(self, base_path: str, num_modules: int = 10):\n        \"\"\"大規模ワークフローのステップを生成\"\"\"\n        steps = []\n        \n        # プロジェクト構造の作成\n        steps.append({\"type\": \"mkdir\", \"cmd\": [base_path]})\n        steps.append({\"type\": \"mkdir\", \"cmd\": [f\"{base_path}/src\"]})\n        steps.append({\"type\": \"mkdir\", \"cmd\": [f\"{base_path}/tests\"]})\n        steps.append({\"type\": \"mkdir\", \"cmd\": [f\"{base_path}/docs\"]})\n        steps.append({\"type\": \"mkdir\", \"cmd\": [f\"{base_path}/build\"]})\n        \n        # 各モジュールの作成\n        for i in range(num_modules):\n            module_name = f\"module_{i}\"\n            \n            # モジュールディレクトリ\n            steps.append({\"type\": \"mkdir\", \"cmd\": [f\"{base_path}/src/{module_name}\"]})\n            \n            # ソースファイル\n            steps.append({\"type\": \"touch\", \"cmd\": [f\"{base_path}/src/{module_name}/__init__.py\"]})\n            steps.append({\"type\": \"touch\", \"cmd\": [f\"{base_path}/src/{module_name}/main.py\"]})\n            steps.append({\"type\": \"touch\", \"cmd\": [f\"{base_path}/src/{module_name}/utils.py\"]})\n            \n            # テストファイル\n            steps.append({\"type\": \"touch\", \"cmd\": [f\"{base_path}/tests/test_{module_name}.py\"]})\n            \n            # ドキュメントファイル\n            steps.append({\"type\": \"touch\", \"cmd\": [f\"{base_path}/docs/{module_name}.md\"]})\n        \n        # 設定ファイル\n        steps.append({\"type\": \"touch\", \"cmd\": [f\"{base_path}/requirements.txt\"]})\n        steps.append({\"type\": \"touch\", \"cmd\": [f\"{base_path}/setup.py\"]})\n        steps.append({\"type\": \"touch\", \"cmd\": [f\"{base_path}/README.md\"]})\n        \n        # ファイルのコピー（依存関係を作る）\n        for i in range(min(5, num_modules)):\n            steps.append({\n                \"type\": \"copy\",\n                \"cmd\": [f\"{base_path}/README.md\", f\"{base_path}/docs/README_{i}.md\"]\n            })\n        \n        # ビルドステップ\n        steps.append({\"type\": \"shell\", \"cmd\": [f\"echo 'Building project in {base_path}'\"]})\n        \n        return steps\n    \n    def test_large_workflow_graph_generation(self, mock_controller, mock_operations, temp_dir):\n        \"\"\"大規模ワークフローのグラフ生成テスト\"\"\"\n        builder = GraphBasedWorkflowBuilder(mock_controller, mock_operations)\n        \n        # 50個のモジュールを持つ大規模ワークフロー\n        steps = self.create_large_workflow_steps(temp_dir, num_modules=50)\n        \n        with patch.object(builder, '_step_to_request') as mock_step_to_request:\n            # モックリクエストを返すように設定\n            mock_request = Mock()\n            mock_request.operation_type = Mock()\n            mock_step_to_request.return_value = mock_request\n            \n            # グラフ生成\n            graph, errors, warnings = builder.build_graph_from_json_steps(steps)\n            \n            # 基本的な検証\n            assert isinstance(graph, RequestExecutionGraph)\n            assert len(graph.nodes) > 0\n            assert len(errors) == 0  # エラーがないことを確認\n            \n            # 依存関係が適切に構築されていることを確認\n            execution_order = graph.get_execution_order()\n            assert len(execution_order) == len(graph.nodes)\n            \n            # 並列実行グループの確認\n            parallel_groups = graph.get_parallel_groups()\n            assert len(parallel_groups) > 1  # 複数のグループに分かれている\n    \n    def test_workflow_roundtrip_conversion(self, mock_controller, mock_operations, temp_dir):\n        \"\"\"ワークフローの往復変換テスト（Graph ↔ Composite）\"\"\"\n        builder = GraphBasedWorkflowBuilder(mock_controller, mock_operations)\n        \n        steps = self.create_large_workflow_steps(temp_dir, num_modules=5)\n        \n        with patch.object(builder, '_step_to_request') as mock_step_to_request:\n            # モックリクエストを返すように設定\n            mock_request = Mock()\n            mock_request.operation_type = Mock()\n            mock_step_to_request.return_value = mock_request\n            \n            # Graph 生成\n            original_graph, _, _ = builder.build_graph_from_json_steps(steps)\n            \n            # Graph → Composite 変換\n            composite = GraphToCompositeAdapter.to_composite_request(original_graph)\n            \n            # Composite → Graph 変換\n            restored_graph = GraphToCompositeAdapter.from_composite_request(\n                composite, extract_dependencies=False\n            )\n            \n            # 基本的な整合性確認\n            assert len(restored_graph.nodes) == len(original_graph.nodes)\n            assert len(composite.requests) == len(original_graph.nodes)\n            \n            # 実行順序の一貫性確認\n            original_order = original_graph.get_execution_order()\n            restored_order = restored_graph.get_execution_order()\n            \n            # 順序が保持されていることを確認（完全一致ではないが、長さは同じ）\n            assert len(original_order) == len(restored_order)\n    \n    def test_complex_dependency_workflow(self, mock_controller, mock_operations, temp_dir):\n        \"\"\"複雑な依存関係を持つワークフローのテスト\"\"\"\n        builder = GraphBasedWorkflowBuilder(mock_controller, mock_operations)\n        \n        # 複雑な依存関係を持つステップを作成\n        steps = [\n            # 基本ディレクトリ\n            {\"type\": \"mkdir\", \"cmd\": [f\"{temp_dir}/project\"]},\n            {\"type\": \"mkdir\", \"cmd\": [f\"{temp_dir}/project/src\"]},\n            {\"type\": \"mkdir\", \"cmd\": [f\"{temp_dir}/project/build\"]},\n            {\"type\": \"mkdir\", \"cmd\": [f\"{temp_dir}/project/dist\"]},\n            \n            # ソースファイル（並列作成可能）\n            {\"type\": \"touch\", \"cmd\": [f\"{temp_dir}/project/src/main.py\"]},\n            {\"type\": \"touch\", \"cmd\": [f\"{temp_dir}/project/src/utils.py\"]},\n            {\"type\": \"touch\", \"cmd\": [f\"{temp_dir}/project/src/config.py\"]},\n            \n            # 設定ファイル（並列作成可能）\n            {\"type\": \"touch\", \"cmd\": [f\"{temp_dir}/project/setup.py\"]},\n            {\"type\": \"touch\", \"cmd\": [f\"{temp_dir}/project/requirements.txt\"]},\n            \n            # ファイルコピー（依存関係あり）\n            {\"type\": \"copy\", \"cmd\": [f\"{temp_dir}/project/src/main.py\", f\"{temp_dir}/project/build/main_backup.py\"]},\n            {\"type\": \"copy\", \"cmd\": [f\"{temp_dir}/project/src/utils.py\", f\"{temp_dir}/project/build/utils_backup.py\"]},\n            \n            # 複数ファイルを使用するビルド（複数の依存関係）\n            {\"type\": \"shell\", \"cmd\": [f\"echo 'Building from {temp_dir}/project/src and {temp_dir}/project/build'\"]},\n            \n            # 最終配布（ビルド後に実行）\n            {\"type\": \"copy\", \"cmd\": [f\"{temp_dir}/project/build/main_backup.py\", f\"{temp_dir}/project/dist/main.py\"]},\n        ]\n        \n        with patch.object(builder, '_step_to_request') as mock_step_to_request:\n            mock_request = Mock()\n            mock_request.operation_type = Mock()\n            mock_step_to_request.return_value = mock_request\n            \n            # グラフ生成\n            graph, errors, warnings = builder.build_graph_from_json_steps(steps)\n            \n            assert len(errors) == 0\n            assert len(graph.nodes) > 0\n            \n            # 実行順序の検証\n            execution_order = graph.get_execution_order()\n            order_dict = {node_id: i for i, node_id in enumerate(execution_order)}\n            \n            # 依存関係のサンプル検証（ディレクトリ作成 → ファイル作成 → コピー）\n            # 具体的な順序はビルダーの実装に依存するが、論理的な順序は保たれるべき\n            \n            # 並列実行グループの確認\n            parallel_groups = graph.get_parallel_groups()\n            \n            # 最初のグループには並列実行可能なディレクトリ作成が含まれるはず\n            first_group = parallel_groups[0] if parallel_groups else []\n            \n            # 並列実行の効果を確認（グループ数が1より多い）\n            assert len(parallel_groups) > 1\n    \n    def test_workflow_validation_and_optimization(self, mock_controller, mock_operations, temp_dir):\n        \"\"\"ワークフローの検証と最適化テスト\"\"\"\n        builder = GraphBasedWorkflowBuilder(mock_controller, mock_operations)\n        \n        steps = self.create_large_workflow_steps(temp_dir, num_modules=3)\n        \n        with patch.object(builder, '_step_to_request') as mock_step_to_request:\n            mock_request = Mock()\n            mock_request.operation_type = Mock()\n            mock_step_to_request.return_value = mock_request\n            \n            # グラフ生成\n            graph, errors, warnings = builder.build_graph_from_json_steps(steps)\n            \n            # 検証\n            is_valid, messages = builder.validate_graph(graph)\n            \n            assert is_valid is True\n            assert len(messages) > 0  # 検証メッセージがある\n            \n            # メッセージに並列実行グループの情報が含まれていることを確認\n            messages_text = ' '.join(messages)\n            assert 'execution groups' in messages_text.lower()\n    \n    def test_error_handling_in_large_workflow(self, mock_controller, mock_operations, temp_dir):\n        \"\"\"大規模ワークフローでのエラーハンドリングテスト\"\"\"\n        builder = GraphBasedWorkflowBuilder(mock_controller, mock_operations)\n        \n        # 意図的にエラーを含むステップを作成\n        steps = [\n            {\"type\": \"mkdir\", \"cmd\": [f\"{temp_dir}/project\"]},\n            {\"type\": \"invalid_step\", \"cmd\": [\"this should fail\"]},  # 無効なステップ\n            {\"type\": \"touch\", \"cmd\": [f\"{temp_dir}/project/file.txt\"]},\n        ]\n        \n        with patch.object(builder, '_step_to_request') as mock_step_to_request:\n            # 無効なステップに対してはNoneを返す\n            def mock_request_func(step):\n                if step.type.value == 'invalid_step':\n                    return None\n                mock_request = Mock()\n                mock_request.operation_type = Mock()\n                return mock_request\n            \n            mock_step_to_request.side_effect = mock_request_func\n            \n            # グラフ生成（エラーがあっても他の有効なステップは処理される）\n            graph, errors, warnings = builder.build_graph_from_json_steps(steps)\n            \n            # 有効なステップは処理されている\n            assert len(graph.nodes) >= 2  # mkdir と touch は処理される\n    \n    def test_memory_usage_large_workflow(self, mock_controller, mock_operations, temp_dir):\n        \"\"\"大規模ワークフローでのメモリ使用量テスト\"\"\"\n        import psutil\n        import os\n        \n        process = psutil.Process(os.getpid())\n        initial_memory = process.memory_info().rss\n        \n        builder = GraphBasedWorkflowBuilder(mock_controller, mock_operations)\n        \n        # 大規模ワークフロー（100モジュール）\n        steps = self.create_large_workflow_steps(temp_dir, num_modules=100)\n        \n        with patch.object(builder, '_step_to_request') as mock_step_to_request:\n            mock_request = Mock()\n            mock_request.operation_type = Mock()\n            mock_step_to_request.return_value = mock_request\n            \n            # グラフ生成\n            graph, errors, warnings = builder.build_graph_from_json_steps(steps)\n            \n            # 実行順序とグループの計算\n            execution_order = graph.get_execution_order()\n            parallel_groups = graph.get_parallel_groups()\n            \n            final_memory = process.memory_info().rss\n            memory_increase = final_memory - initial_memory\n            \n            # 100モジュールで50MB以下のメモリ増加であるべき\n            assert memory_increase < 50 * 1024 * 1024  # 50MB\n            \n            # 機能は正常に動作している\n            assert len(execution_order) > 100\n            assert len(parallel_groups) > 1\n    \n    def test_workflow_execution_simulation(self, mock_controller, mock_operations, temp_dir):\n        \"\"\"ワークフロー実行のシミュレーションテスト\"\"\"\n        builder = GraphBasedWorkflowBuilder(mock_controller, mock_operations)\n        \n        steps = self.create_large_workflow_steps(temp_dir, num_modules=5)\n        \n        # 実行時間の異なるモックリクエストを作成\n        def create_timed_request(execution_time=0.01):\n            import time\n            request = Mock()\n            request.operation_type = Mock()\n            request.allow_failure = False\n            \n            def mock_execute(driver=None):\n                time.sleep(execution_time)\n                return OperationResult(success=True)\n            \n            request.execute.side_effect = mock_execute\n            return request\n        \n        with patch.object(builder, '_step_to_request') as mock_step_to_request:\n            mock_step_to_request.return_value = create_timed_request(0.001)  # 1ms\n            \n            # グラフ生成\n            graph, errors, warnings = builder.build_graph_from_json_steps(steps)\n            \n            # 順次実行のシミュレーション\n            import time\n            start_time = time.time()\n            sequential_results = graph.execute_sequential()\n            sequential_time = time.time() - start_time\n            \n            # 新しいグラフで並列実行のシミュレーション\n            graph2, _, _ = builder.build_graph_from_json_steps(steps)\n            \n            start_time = time.time()\n            parallel_results = graph2.execute_parallel(max_workers=4)\n            parallel_time = time.time() - start_time\n            \n            # 結果の検証\n            assert len(sequential_results) == len(parallel_results)\n            assert all(r.success for r in sequential_results)\n            assert all(r.success for r in parallel_results)\n            \n            # 大規模ワークフローでは並列実行の効果があるはず\n            if len(graph.nodes) > 10:\n                assert parallel_time <= sequential_time  # 並列実行は同等以上の速度