#!/usr/bin/env python3
"""
ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼

ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ï¼š
- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ã®æ•´åˆæ€§
- å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®æ¤œå‡º
- ä¾å­˜é–¢ä¿‚ã®æ–¹å‘æ€§
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™
"""

import ast
import sys
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Tuple

sys.path.insert(0, str(Path(__file__).parent.parent))

from infrastructure.file_handler import FileHandler
from infrastructure.logger import Logger
from infrastructure.system_operations import SystemOperations


@dataclass(frozen=True)
class ArchitectureIssue:
    """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å•é¡Œã‚’è¡¨ç¾ã™ã‚‹ä¸å¤‰ãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    file: str
    issue_type: str
    description: str
    severity: str
    details: str = ""


class ImportAnalyzer(ast.NodeVisitor):
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–¢ä¿‚ã‚’åˆ†æ"""

    def __init__(self, filename: str):
        self.filename = filename
        self.imports: List[str] = []
        self.from_imports: List[Tuple[str, List[str]]] = []

    def visit_Import(self, node: ast.Import):
        for alias in node.names:
            self.imports.append(alias.name)

    def visit_ImportFrom(self, node: ast.ImportFrom):
        if node.module:
            names = [alias.name for alias in node.names]
            self.from_imports.append((node.module, names))


def analyze_imports(file_path: str, file_handler: FileHandler) -> Tuple[List[str], List[Tuple[str, List[str]]]]:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’åˆ†æ"""
    try:
        content = file_handler.read_text(file_path, encoding='utf-8')

        tree = ast.parse(content, filename=file_path)
        analyzer = ImportAnalyzer(file_path)
        analyzer.visit(tree)

        return analyzer.imports, analyzer.from_imports
    except Exception as e:
        raise Exception(f"Failed to analyze imports in {file_path}: {e}") from e


def check_file_size_limits(directory: str, file_handler: FileHandler) -> List[ArchitectureIssue]:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯"""
    issues = []
    python_files = file_handler.glob("**/*.py", directory)

    for file_path in python_files:
        try:
            content = file_handler.read_text(file_path, encoding='utf-8')
            line_count = len(content.splitlines())

            # æ¥µç«¯ã«å¤§ãã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿è­¦å‘Š (800è¡Œä»¥ä¸Š)
            extreme_threshold = 800

            if line_count >= extreme_threshold:
                severity = 'warning'
                issues.append(ArchitectureIssue(
                    file=str(file_path),
                    issue_type='file_size',
                    description=f'ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º {line_count} è¡Œï¼ˆæ¨å¥¨: {extreme_threshold}è¡Œæœªæº€ï¼‰',
                    severity=severity,
                    details=f'æ¥µç«¯ã«å¤§ãã„ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ ({line_count - extreme_threshold} è¡Œè¶…é)'
                ))
        except Exception:
            continue

    return issues


def check_module_structure(directory: str) -> List[ArchitectureIssue]:
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ãƒã‚§ãƒƒã‚¯"""
    issues = []

    # æœŸå¾…ã•ã‚Œã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ï¼ˆworkflow.builderã¯å‰Šé™¤æ¸ˆã¿ï¼‰

    # workflow.builderãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯å‰Šé™¤æ¸ˆã¿ã®ãŸã‚ã€ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—

    return issues


def detect_circular_imports(directory: str, system_ops: SystemOperations, file_handler: FileHandler) -> List[ArchitectureIssue]:
    """å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®æ¤œå‡º"""
    issues = []
    python_files = file_handler.glob("**/*.py", directory)

    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    module_to_file = {}
    file_to_module = {}

    for file_path in python_files:
        # ç›¸å¯¾ãƒ‘ã‚¹ã‹ã‚‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã‚’ç”Ÿæˆ
        rel_path = Path(file_path).relative_to(Path(directory))
        module_name = str(rel_path).replace('/', '.').replace('\\', '.').replace('.py', '')
        module_to_file[module_name] = str(file_path)
        file_to_module[str(file_path)] = module_name

    # ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
    dependencies = defaultdict(set)

    for file_path in python_files:
        imports, from_imports = analyze_imports(str(file_path))
        current_module = file_to_module[str(file_path)]

        # å†…éƒ¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ã¿ã‚’å¯¾è±¡
        for imp in imports:
            if imp.startswith('src.'):
                clean_imp = imp.replace('src.', '')
                if clean_imp in module_to_file:
                    dependencies[current_module].add(clean_imp)

        for module, _names in from_imports:
            if module and module.startswith('src.'):
                clean_module = module.replace('src.', '')
                if clean_module in module_to_file:
                    dependencies[current_module].add(clean_module)

    # å¾ªç’°ä¾å­˜ã®æ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
    visited = set()
    rec_stack = set()

    def dfs(module: str, path: List[str]) -> bool:
        if module in rec_stack:
            # å¾ªç’°ç™ºè¦‹
            cycle_start = path.index(module)
            cycle = path[cycle_start:] + [module]
            issues.append(ArchitectureIssue(
                file=module_to_file[module],
                issue_type='circular_import',
                description=f'å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œå‡º: {" -> ".join(cycle)}',
                severity='error',
                details='ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã§å¾ªç’°ä¾å­˜ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™'
            ))
            return True

        if module in visited:
            return False

        visited.add(module)
        rec_stack.add(module)

        for dep in dependencies[module]:
            if dfs(dep, [*path, module]):
                return True

        rec_stack.remove(module)
        return False

    for module in list(dependencies.keys()):
        if module not in visited:
            dfs(module, [])

    return issues


def check_dependency_direction(directory: str, file_handler: FileHandler) -> List[ArchitectureIssue]:
    """ä¾å­˜é–¢ä¿‚ã®æ–¹å‘æ€§ãƒã‚§ãƒƒã‚¯"""
    issues = []

    # æœŸå¾…ã•ã‚Œã‚‹ä¾å­˜é–¢ä¿‚ã®éšå±¤ï¼ˆworkflow.builderã¯å‰Šé™¤æ¸ˆã¿ï¼‰
    hierarchy = {
        'workflow.step': 0,  # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—
        'domain.requests': 1,  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼
        'application': 2   # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼
    }

    python_files = file_handler.glob("**/*.py", directory)

    for file_path in python_files:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã©ã®éšå±¤ã«å±ã™ã‚‹ã‹åˆ¤å®š
        current_level = None
        current_module = None

        for module, level in hierarchy.items():
            if module.replace('.', '/') in str(file_path):
                current_level = level
                current_module = module
                break

        if current_level is None:
            continue

        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
        imports, from_imports = analyze_imports(str(file_path), file_handler)

        all_imports = imports + [module for module, _ in from_imports]

        for imp in all_imports:
            if imp.startswith('src.'):
                # Skip utils imports as they are cross-cutting concerns
                if imp.startswith('src.utils.'):
                    continue

                for target_module, target_level in hierarchy.items():
                    if target_module.replace('.', '/') in imp:
                        if target_level >= current_level and target_module != current_module:
                            issues.append(ArchitectureIssue(
                                file=str(file_path),
                                issue_type='wrong_dependency_direction',
                                description=f'{current_module} (level {current_level}) ãŒ {target_module} (level {target_level}) ã«ä¾å­˜',
                                severity='warning',
                                details='ä¸‹ä½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒä¸Šä½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ä¾å­˜ã—ã¦ã„ã¾ã™'
                            ))
                        break

    return issues


def calculate_module_metrics(directory: str, file_handler: FileHandler) -> Dict[str, any]:
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
    python_files = file_handler.glob("**/*.py", directory)

    total_files = len(python_files)
    total_lines = 0
    max_file_size = 0
    max_file_path = ""

    module_counts = defaultdict(int)

    for file_path in python_files:
        try:
            content = file_handler.read_text(file_path, encoding='utf-8')
            line_count = len(content.splitlines())
            total_lines += line_count

            if line_count > max_file_size:
                max_file_size = line_count
                max_file_path = str(file_path)

            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
            from pathlib import Path
            rel_path = Path(file_path).relative_to(Path(directory))
            if '/' in str(rel_path):
                module = str(rel_path).split('/')[0]
                module_counts[module] += 1
        except Exception:
            continue

    return {
        'total_files': total_files,
        'total_lines': total_lines,
        'average_file_size': total_lines / total_files if total_files > 0 else 0,
        'max_file_size': max_file_size,
        'max_file_path': max_file_path,
        'module_distribution': dict(module_counts)
    }


def main(system_ops: SystemOperations, file_handler: FileHandler, logger: Logger):
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    argv = system_ops.get_argv()
    if len(argv) < 2:
        system_ops.print_stdout("ä½¿ç”¨æ–¹æ³•: python3 architecture_quality_check.py <directory>")
        system_ops.exit(1)

    directory = argv[1]

    logger.info("ğŸ—ï¸  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å“è³ªãƒã‚§ãƒƒã‚¯é–‹å§‹...")
    logger.info("")

    all_issues = []

    # å„ç¨®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
    checks = [
        ("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™", lambda d: check_file_size_limits(d, file_handler)),
        ("ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ", check_module_structure),
        ("å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", lambda d: detect_circular_imports(d, system_ops, file_handler)),
        ("ä¾å­˜é–¢ä¿‚æ–¹å‘", lambda d: check_dependency_direction(d, file_handler))
    ]

    for check_name, check_func in checks:
        logger.info(f"ğŸ” {check_name}ãƒã‚§ãƒƒã‚¯ä¸­...")
        issues = check_func(directory)
        all_issues.extend(issues)
        logger.info(f"  {'âœ“' if not issues else 'âš ï¸'} {len(issues)} ä»¶ã®å•é¡Œ")

    logger.info("")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    metrics = calculate_module_metrics(directory, file_handler)
    logger.info("ğŸ“Š ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
    logger.info(f"  ğŸ“ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {metrics['total_files']}")
    logger.info(f"  ğŸ“ ç·è¡Œæ•°: {metrics['total_lines']:,}")
    logger.info(f"  ğŸ“ å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {metrics['average_file_size']:.1f} è¡Œ")
    logger.info(f"  ğŸ“ˆ æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {metrics['max_file_size']} è¡Œ")
    logger.info(f"     ({Path(metrics['max_file_path']).name})")
    logger.info("")

    logger.info("ğŸ—‚ï¸  ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å¸ƒ:")
    for module, count in sorted(metrics['module_distribution'].items()):
        logger.info(f"  {module}: {count} ãƒ•ã‚¡ã‚¤ãƒ«")
    logger.info("")

    # å•é¡Œã®è¡¨ç¤º
    if all_issues:
        error_count = sum(1 for issue in all_issues if issue.severity == 'error')
        warning_count = sum(1 for issue in all_issues if issue.severity == 'warning')

        logger.info("ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")

        # ã‚¨ãƒ©ãƒ¼ã‚’å…ˆã«è¡¨ç¤º
        errors = [issue for issue in all_issues if issue.severity == 'error']
        warnings = [issue for issue in all_issues if issue.severity == 'warning']

        if errors:
            logger.info("\nâŒ ã‚¨ãƒ©ãƒ¼:")
            for issue in errors[:5]:
                logger.info(f"  {Path(issue.file).name}: {issue.description}")
            if len(errors) > 5:
                logger.info(f"  ... ä»– {len(errors) - 5} ä»¶")

        if warnings:
            logger.info("\nâš ï¸ è­¦å‘Š:")
            for issue in warnings[:5]:
                logger.info(f"  {Path(issue.file).name}: {issue.description}")
            if len(warnings) > 5:
                logger.info(f"  ... ä»– {len(warnings) - 5} ä»¶")

        logger.info(f"\nğŸ“Š ã‚µãƒãƒªãƒ¼: âŒ {error_count} ã‚¨ãƒ©ãƒ¼, âš ï¸ {warning_count} è­¦å‘Š")

        if error_count > 0:
            logger.info("\nğŸ’¥ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¨ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
            system_ops.exit(1)
        else:
            logger.info("\nâš ï¸ è­¦å‘ŠãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ”¹å–„ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            system_ops.exit(0)
    else:
        logger.info("âœ… ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å“è³ªåŸºæº–ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™ï¼")
        system_ops.exit(0)


if __name__ == "__main__":
    # äº’æ›æ€§ç¶­æŒ: æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆã§å‹•ä½œã™ã‚‹ã‚ˆã†ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ä¿æŒ
    import os
    import sys

    from infrastructure.file_handler import create_file_handler
    from infrastructure.system_operations_impl import SystemOperationsImpl

    # ä¾å­˜æ€§æ³¨å…¥ç”¨ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½œæˆ
    class OSProvider:
        def getcwd(self): return os.getcwd()
        def chdir(self, path): os.chdir(path)
        def path_exists(self, path): return os.path.exists(path)
        def isfile(self, path): return os.path.isfile(path)
        def isdir(self, path): return os.path.isdir(path)
        def makedirs(self, path, exist_ok): os.makedirs(path, exist_ok=exist_ok)
        def remove(self, path): os.remove(path)
        def rmdir(self, path): os.rmdir(path)
        def listdir(self, path): return os.listdir(path)
        def get_env(self, key): return os.environ.get(key)
        def set_env(self, key, value): os.environ[key] = value

    class SysProvider:
        def exit(self, code): sys.exit(code)
        def get_argv(self): return sys.argv

    system_ops = SystemOperationsImpl(OSProvider(), SysProvider())
    file_handler = create_file_handler(mock=False, file_operations=None)
    main(system_ops, file_handler)
