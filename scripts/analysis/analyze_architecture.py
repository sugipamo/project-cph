#!/usr/bin/env python3
"""
ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç†è«–ã«åŸºã¥ããƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ãƒ»ä¾å­˜é–¢ä¿‚ã®åˆ†æ
"""
import ast
from collections import defaultdict
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Dict, List, Optional, Set

from infrastructure.logger import Logger


@dataclass
class ModuleMetrics:
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆMartin's Metricsï¼‰"""
    name: str
    afferent_coupling: int  # Ca: ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ä¾å­˜ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°
    efferent_coupling: int  # Ce: ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒä¾å­˜ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°
    instability: float      # I = Ce / (Ca + Ce)
    abstractness: float     # A: æŠ½è±¡ã‚¯ãƒ©ã‚¹ãƒ»ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å‰²åˆ
    distance: float         # D: Main Sequence ã‹ã‚‰ã®è·é›¢
    lines_of_code: int
    complexity_score: float


@dataclass
class LayerViolation:
    """ãƒ¬ã‚¤ãƒ¤ãƒ¼é•å"""
    from_module: str
    to_module: str
    from_layer: str
    to_layer: str
    violation_type: str


@dataclass
class ArchitecturalAnalysis:
    """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æçµæœ"""
    module_metrics: List[ModuleMetrics]
    layer_violations: List[LayerViolation]
    circular_dependencies: List[List[str]]
    hotspots: List[str]  # å•é¡Œã®ã‚ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    recommendations: List[str]


class ArchitectureAnalyzer:
    def __init__(self, logger: Logger):
        self.logger = logger
        # æœŸå¾…ã•ã‚Œã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹é€ ï¼ˆClean Architectureï¼‰
        self.expected_layers = {
            'domain': {
                'level': 0,  # æœ€å†…å±¤
                'description': 'Business logic, entities, value objects',
                'allowed_dependencies': []
            },
            'application': {
                'level': 1,
                'description': 'Use cases, application services',
                'allowed_dependencies': ['domain']
            },
            'infrastructure': {
                'level': 2,
                'description': 'External adapters, repositories, drivers',
                'allowed_dependencies': ['domain', 'application']
            },
            'context': {
                'level': 1,
                'description': 'Context and configuration',
                'allowed_dependencies': ['domain']
            },
            'workflow': {
                'level': 1,
                'description': 'Workflow orchestration',
                'allowed_dependencies': ['domain', 'application']
            },
            'utils': {
                'level': 0,
                'description': 'Utilities and helpers',
                'allowed_dependencies': []
            }
        }

        self.module_dependencies: Dict[str, Set[str]] = defaultdict(set)
        self.module_info: Dict[str, Dict] = {}
        self.reverse_dependencies: Dict[str, Set[str]] = defaultdict(set)

    def analyze_project(self, src_dir: Path) -> ArchitecturalAnalysis:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’åˆ†æ"""
        self.logger.info("ğŸ—ï¸  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æé–‹å§‹...")

        # 1. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±åé›†
        self._collect_module_info(src_dir)

        # 2. ä¾å­˜é–¢ä¿‚è§£æ
        self._analyze_dependencies(src_dir)

        # 3. ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        module_metrics = self._calculate_metrics()

        # 4. ãƒ¬ã‚¤ãƒ¤ãƒ¼é•åæ¤œå‡º
        layer_violations = self._detect_layer_violations()

        # 5. å¾ªç’°ä¾å­˜æ¤œå‡º
        circular_deps = self._detect_circular_dependencies()

        # 6. ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆç‰¹å®š
        hotspots = self._identify_hotspots(module_metrics)

        # 7. æ¨å¥¨äº‹é …ç”Ÿæˆ
        recommendations = self._generate_recommendations(
            module_metrics, layer_violations, circular_deps, hotspots
        )

        return ArchitecturalAnalysis(
            module_metrics=module_metrics,
            layer_violations=layer_violations,
            circular_dependencies=circular_deps,
            hotspots=hotspots,
            recommendations=recommendations
        )

    def _collect_module_info(self, src_dir: Path) -> None:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’åé›†"""
        for py_file in src_dir.rglob("*.py"):
            if '__pycache__' in str(py_file):
                continue

            module_name = self._path_to_module(py_file, src_dir)

            try:
                with open(py_file, encoding='utf-8') as f:
                    content = f.read()
                    tree = ast.parse(content)

                # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’åé›†
                classes = len([n for n in ast.walk(tree) if isinstance(n, ast.ClassDef)])
                functions = len([n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)])
                abstract_items = len([
                    n for n in ast.walk(tree)
                    if isinstance(n, ast.ClassDef) and
                    any('ABC' in base.id if isinstance(base, ast.Name) else False
                        for base in n.bases)
                ])

                self.module_info[module_name] = {
                    'file_path': py_file,
                    'lines_of_code': len(content.splitlines()),
                    'classes': classes,
                    'functions': functions,
                    'abstract_items': abstract_items,
                    'total_items': classes + functions
                }

            except Exception as e:
                self.logger.warning(f"Failed to analyze {py_file}: {e}")

    def _analyze_dependencies(self, src_dir: Path) -> None:
        """ä¾å­˜é–¢ä¿‚ã‚’è§£æ"""
        for py_file in src_dir.rglob("*.py"):
            if '__pycache__' in str(py_file):
                continue

            module_name = self._path_to_module(py_file, src_dir)

            try:
                with open(py_file, encoding='utf-8') as f:
                    tree = ast.parse(f.read())

                for node in ast.walk(tree):
                    if isinstance(node, ast.ImportFrom) and node.module:
                        if node.module.startswith('src.'):
                            imported_module = node.module
                            self.module_dependencies[module_name].add(imported_module)
                            self.reverse_dependencies[imported_module].add(module_name)

                    elif isinstance(node, ast.Import):
                        for alias in node.names:
                            if alias.name.startswith('src.'):
                                self.module_dependencies[module_name].add(alias.name)
                                self.reverse_dependencies[alias.name].add(module_name)

            except Exception:
                pass

    def _calculate_metrics(self) -> List[ModuleMetrics]:
        """Martin's Metrics ã‚’è¨ˆç®—"""
        metrics = []

        for module_name, info in self.module_info.items():
            # Ca: Afferent Coupling (å…¥åŠ›çµåˆåº¦)
            ca = len(self.reverse_dependencies[module_name])

            # Ce: Efferent Coupling (å‡ºåŠ›çµåˆåº¦)
            ce = len(self.module_dependencies[module_name])

            # I: Instability (ä¸å®‰å®šæ€§)
            instability = ce / (ca + ce) if (ca + ce) > 0 else 0

            # A: Abstractness (æŠ½è±¡åº¦)
            total_items = info['total_items']
            abstractness = info['abstract_items'] / total_items if total_items > 0 else 0

            # D: Distance from Main Sequence
            # Main Sequence: A + I = 1
            distance = abs(abstractness + instability - 1)

            # è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢ï¼ˆç‹¬è‡ªæŒ‡æ¨™ï¼‰
            complexity_score = (ce * 2) + (ca * 1.5) + (info['lines_of_code'] / 100)

            metrics.append(ModuleMetrics(
                name=module_name,
                afferent_coupling=ca,
                efferent_coupling=ce,
                instability=instability,
                abstractness=abstractness,
                distance=distance,
                lines_of_code=info['lines_of_code'],
                complexity_score=complexity_score
            ))

        return sorted(metrics, key=lambda x: x.distance, reverse=True)

    def _detect_layer_violations(self) -> List[LayerViolation]:
        """ãƒ¬ã‚¤ãƒ¤ãƒ¼é•åã‚’æ¤œå‡º"""
        violations = []

        for from_module, dependencies in self.module_dependencies.items():
            from_layer = self._get_layer_from_module(from_module)

            for to_module in dependencies:
                to_layer = self._get_layer_from_module(to_module)

                if from_layer and to_layer:
                    # ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ«ãƒ¼ãƒ«é•åãƒã‚§ãƒƒã‚¯
                    violation_type = self._check_layer_violation(from_layer, to_layer, from_module, to_module)

                    if violation_type:
                        violations.append(LayerViolation(
                            from_module=from_module,
                            to_module=to_module,
                            from_layer=from_layer,
                            to_layer=to_layer,
                            violation_type=violation_type
                        ))

        return violations

    def _detect_circular_dependencies(self) -> List[List[str]]:
        """å¾ªç’°ä¾å­˜ã‚’æ¤œå‡º"""
        visited = set()
        rec_stack = set()
        cycles = []

        def dfs(module: str, path: List[str]) -> None:
            if module in rec_stack:
                # å¾ªç’°ç™ºè¦‹
                cycle_start = path.index(module)
                cycle = path[cycle_start:] + [module]
                cycles.append(cycle)
                return

            if module in visited:
                return

            visited.add(module)
            rec_stack.add(module)
            path.append(module)

            for dep in self.module_dependencies[module]:
                if dep in self.module_info:  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿
                    dfs(dep, path.copy())

            rec_stack.remove(module)

        for module in self.module_info:
            if module not in visited:
                dfs(module, [])

        return cycles

    def _identify_hotspots(self, metrics: List[ModuleMetrics]) -> List[str]:
        """å•é¡Œã®ã‚ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆï¼‰ã‚’ç‰¹å®š"""
        hotspots = []

        for metric in metrics:
            issues = []

            # é«˜ã„ä¸å®‰å®šæ€§
            if metric.instability > 0.8:
                issues.append("high_instability")

            # Main Sequenceã‹ã‚‰é›¢ã‚Œã¦ã„ã‚‹
            if metric.distance > 0.7:
                issues.append("architectural_violation")

            # é«˜ã„çµåˆåº¦
            if metric.efferent_coupling > 10:
                issues.append("high_coupling")

            # å¤§ãã™ãã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
            if metric.lines_of_code > 500:
                issues.append("too_large")

            if issues:
                hotspots.append(f"{metric.name} ({', '.join(issues)})")

        return hotspots

    def _generate_recommendations(self, metrics: List[ModuleMetrics],
                                violations: List[LayerViolation],
                                circular_deps: List[List[str]],
                                hotspots: List[str]) -> List[str]:
        """æ”¹å–„æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = []

        if circular_deps:
            recommendations.append(f"ğŸ”„ {len(circular_deps)}å€‹ã®å¾ªç’°ä¾å­˜ã‚’è§£æ¶ˆã—ã¦ãã ã•ã„")

        if violations:
            recommendations.append(f"ğŸ—ï¸  {len(violations)}å€‹ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼é•åã‚’ä¿®æ­£ã—ã¦ãã ã•ã„")

        # é«˜çµåˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
        high_coupling = [m for m in metrics if m.efferent_coupling > 8]
        if high_coupling:
            recommendations.append(f"ğŸ”— {len(high_coupling)}å€‹ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®çµåˆåº¦ã‚’ä¸‹ã’ã¦ãã ã•ã„")

        # å¤§ãã™ãã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
        large_modules = [m for m in metrics if m.lines_of_code > 400]
        if large_modules:
            recommendations.append(f"ğŸ“ {len(large_modules)}å€‹ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ†å‰²ã—ã¦ãã ã•ã„")

        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é•å
        arch_violations = [m for m in metrics if m.distance > 0.6]
        if arch_violations:
            recommendations.append(f"ğŸ“ {len(arch_violations)}å€‹ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŸå‰‡é•å")

        if not recommendations:
            recommendations.append("âœ¨ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯è‰¯å¥½ãªçŠ¶æ…‹ã§ã™ï¼")

        return recommendations

    def _path_to_module(self, file_path: Path, src_dir: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã«å¤‰æ›"""
        try:
            relative_path = file_path.relative_to(src_dir)
            parts = relative_path.parts

            module_parts = []
            for part in parts:
                if part.endswith('.py'):
                    if part != '__init__.py':
                        module_parts.append(part[:-3])
                else:
                    module_parts.append(part)

            return 'src.' + '.'.join(module_parts) if module_parts else 'src'
        except ValueError as e:
            raise ValueError(f"Failed to convert file path to module: {file_path}") from e

    def _get_layer_from_module(self, module_name: str) -> Optional[str]:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã‹ã‚‰ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ç‰¹å®š"""
        if not module_name.startswith('src.'):
            return None

        parts = module_name.split('.')
        if len(parts) < 2:
            return None

        layer_name = parts[1]
        return layer_name if layer_name in self.expected_layers else None

    def _check_layer_violation(self, from_layer: str, to_layer: str,
                             from_module: str, to_module: str) -> Optional[str]:
        """ãƒ¬ã‚¤ãƒ¤ãƒ¼é•åã‚’ãƒã‚§ãƒƒã‚¯"""
        if from_layer not in self.expected_layers or to_layer not in self.expected_layers:
            return None

        allowed_deps = self.expected_layers[from_layer]['allowed_dependencies']

        if to_layer not in allowed_deps:
            from_level = self.expected_layers[from_layer]['level']
            to_level = self.expected_layers[to_layer]['level']

            if from_level < to_level:
                return "upward_dependency"  # å†…å±¤ãŒå¤–å±¤ã«ä¾å­˜
            if from_level == to_level and from_layer != to_layer:
                return "cross_layer_dependency"  # åŒãƒ¬ãƒ™ãƒ«é–“ã®ä¾å­˜
            return "forbidden_dependency"  # ç¦æ­¢ã•ã‚ŒãŸä¾å­˜

        return None


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    from infrastructure.logger import create_logger
    from infrastructure.system_operations_impl import LocalSystemOperations

    logger = create_logger(verbose=False, silent=False, system_operations=None)
    system_ops = LocalSystemOperations()

    argv = system_ops.get_argv()
    if len(argv) < 2:
        logger.info("Usage: python analyze_architecture.py <src_directory>")
        system_ops.exit(1)

    src_dir = Path(argv[1])
    analyzer = ArchitectureAnalyzer(logger)

    # åˆ†æå®Ÿè¡Œ
    analysis = analyzer.analyze_project(src_dir)

    # çµæœè¡¨ç¤º
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æçµæœ")
    logger.info("=" * 60)

    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆä¸Šä½å•é¡Œï¼‰
    logger.info("\nğŸ¯ å•é¡Œã®ã‚ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Top 10):")
    for i, metric in enumerate(analysis.module_metrics[:10], 1):
        logger.info(f"{i:2d}. {metric.name}")
        logger.info(f"    Distance: {metric.distance:.3f}, "
              f"Instability: {metric.instability:.3f}, "
              f"Coupling: {metric.efferent_coupling}")

    # ãƒ¬ã‚¤ãƒ¤ãƒ¼é•å
    if analysis.layer_violations:
        logger.info(f"\nğŸ—ï¸  ãƒ¬ã‚¤ãƒ¤ãƒ¼é•å ({len(analysis.layer_violations)}ä»¶):")
        for violation in analysis.layer_violations[:5]:
            logger.info(f"   {violation.from_layer} -> {violation.to_layer}: "
                  f"{violation.violation_type}")

    # å¾ªç’°ä¾å­˜
    if analysis.circular_dependencies:
        logger.info(f"\nğŸ”„ å¾ªç’°ä¾å­˜ ({len(analysis.circular_dependencies)}ä»¶):")
        for cycle in analysis.circular_dependencies[:3]:
            logger.info(f"   {' -> '.join(cycle)}")

    # æ¨å¥¨äº‹é …
    logger.info("\nğŸ’¡ æ¨å¥¨äº‹é …:")
    for rec in analysis.recommendations:
        logger.info(f"   {rec}")

    # JSONå‡ºåŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if '--json' in argv:
        output_file = 'architecture_analysis.json'
        with open(output_file, 'w', encoding='utf-8'):
            # dataclassã‚’dictã«å¤‰æ›
            {
                'module_metrics': [asdict(m) for m in analysis.module_metrics],
                'layer_violations': [asdict(v) for v in analysis.layer_violations],
                'circular_dependencies': analysis.circular_dependencies,
                'hotspots': analysis.hotspots,
                'recommendations': analysis.recommendations
            }
            # JSONæ›¸ãè¾¼ã¿ã¯ä¾å­˜æ€§æ³¨å…¥ãŒå¿…è¦
            # json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"\nğŸ“„ è©³ç´°çµæœã‚’ {output_file} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
