import ast
import os
import sys
import json
import shutil
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, Any, Union
from dataclasses import dataclass, field
from collections import defaultdict
from datetime import datetime
import re

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
from src_check.models.check_result import CheckResult, FailureLocation


@dataclass
class FileMove:
    source: Path
    destination: Path
    reason: str
    element_type: str  # 'function', 'class', 'module'
    element_name: str


@dataclass
class ImportUpdate:
    file_path: Path
    old_import: str
    new_import: str
    line_number: int


@dataclass
class RollbackInfo:
    timestamp: str
    moves: List[FileMove]
    import_updates: List[ImportUpdate]
    backup_dir: Path


class LogicalFileOrganizer:
    """è«–ç†çš„ãªæ§‹é€ ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ•´ç†ã™ã‚‹ãƒ„ãƒ¼ãƒ«"""
    
    # è«–ç†çš„ãªã‚«ãƒ†ã‚´ãƒªã¨å¯¾å¿œã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€å
    LOGICAL_CATEGORIES = {
        # ãƒ‡ãƒ¼ã‚¿å±¤
        'models': ['model', 'entity', 'schema', 'dto'],
        'repositories': ['repository', 'repo', 'dao'],
        
        # ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å±¤
        'services': ['service', 'business', 'logic'],
        'use_cases': ['usecase', 'use_case', 'interactor'],
        
        # ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å±¤
        'controllers': ['controller', 'handler', 'endpoint'],
        'views': ['view', 'template', 'ui'],
        
        # ã‚¤ãƒ³ãƒ•ãƒ©å±¤
        'infrastructure': ['infra', 'infrastructure', 'external'],
        'adapters': ['adapter', 'connector', 'client'],
        
        # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
        'utils': ['util', 'utils', 'helper', 'helpers'],
        'validators': ['validator', 'validation', 'check'],
        'formatters': ['formatter', 'format', 'serializer'],
        'parsers': ['parser', 'parse', 'reader'],
        
        # è¨­å®šãƒ»å®šæ•°
        'config': ['config', 'configuration', 'settings'],
        'constants': ['constant', 'const', 'enum'],
        
        # ãƒ†ã‚¹ãƒˆ
        'tests': ['test', 'tests', 'spec'],
    }
    
    def __init__(self, src_dir: str, dry_run: bool = True):
        self.src_dir = Path(src_dir)
        self.dry_run = dry_run
        self.file_moves: List[FileMove] = []
        self.import_updates: List[ImportUpdate] = []
        self.rollback_info: Optional[RollbackInfo] = None
        
    def organize(self) -> Tuple[List[FileMove], List[ImportUpdate]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è«–ç†çš„ã«æ•´ç†"""
        print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã‚’{'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³' if self.dry_run else 'å®Ÿè¡Œ'}ã—ã¾ã™: {self.src_dir}")
        
        # 1. ç¾åœ¨ã®æ§‹é€ ã‚’åˆ†æ
        self._analyze_current_structure()
        
        # 2. è«–ç†çš„ãªç§»å‹•è¨ˆç”»ã‚’ä½œæˆ
        self._create_move_plan()
        
        # 3. ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°è¨ˆç”»ã‚’ä½œæˆ
        self._create_import_update_plan()
        
        # 4. å®Ÿè¡Œã¾ãŸã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        if not self.dry_run:
            self._execute_organization()
        else:
            self._show_simulation()
            
        return self.file_moves, self.import_updates
        
    def _analyze_current_structure(self) -> None:
        """ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’åˆ†æ"""
        print("\nğŸ“Š ç¾åœ¨ã®æ§‹é€ ã‚’åˆ†æä¸­...")
        
        for py_file in self.src_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "_test.py" in str(py_file):
                continue
                
            logical_category = self._determine_logical_category(py_file)
            if logical_category:
                ideal_path = self._get_ideal_path(py_file, logical_category)
                
                if ideal_path != py_file:
                    move = FileMove(
                        source=py_file,
                        destination=ideal_path,
                        reason=f"{logical_category}ã‚«ãƒ†ã‚´ãƒªã«å±ã™ã‚‹ãŸã‚",
                        element_type=self._get_element_type(py_file),
                        element_name=py_file.stem
                    )
                    self.file_moves.append(move)
                    
    def _determine_logical_category(self, file_path: Path) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è«–ç†çš„ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š"""
        file_name = file_path.stem.lower()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰åˆ¤å®š
        for category, patterns in self.LOGICAL_CATEGORIES.items():
            for pattern in patterns:
                if pattern in file_name:
                    return category
                    
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‹ã‚‰åˆ¤å®š
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_name = node.name.lower()
                    for category, patterns in self.LOGICAL_CATEGORIES.items():
                        for pattern in patterns:
                            if pattern in class_name:
                                return category
                                
        except Exception:
            pass
            
        return None
        
    def _get_ideal_path(self, current_path: Path, category: str) -> Path:
        """ç†æƒ³çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        category_dir = self.src_dir / category
        
        # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®šï¼ˆä¾‹: user_repository.py â†’ repositories/user/ï¼‰
        file_stem = current_path.stem
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‰Šé™¤ã—ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã‚’æŠ½å‡º
        entity_name = file_stem
        for _, patterns in self.LOGICAL_CATEGORIES.items():
            for pattern in patterns:
                entity_name = entity_name.replace(f"_{pattern}", "").replace(f"{pattern}_", "")
                
        # ç‰¹å®šã®ã‚«ãƒ†ã‚´ãƒªã§ã¯ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ¥ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        if category in ['repositories', 'services', 'controllers', 'models']:
            if entity_name and entity_name != file_stem:
                return category_dir / entity_name / current_path.name
                
        return category_dir / current_path.name
        
    def _get_element_type(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ç´ ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            tree = ast.parse(content)
            
            has_classes = any(isinstance(node, ast.ClassDef) for node in ast.walk(tree))
            has_functions = any(isinstance(node, ast.FunctionDef) for node in ast.walk(tree))
            
            if has_classes:
                return 'class'
            elif has_functions:
                return 'function'
            else:
                return 'module'
                
        except Exception:
            return 'module'
            
    def _create_move_plan(self) -> None:
        """ç§»å‹•è¨ˆç”»ã‚’æœ€é©åŒ–"""
        # ä¾å­˜é–¢ä¿‚ã‚’è€ƒæ…®ã—ã¦ç§»å‹•é †åºã‚’æ±ºå®š
        self.file_moves.sort(key=lambda m: (
            # ã¾ãšãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚„ãƒ¢ãƒ‡ãƒ«ãªã©åŸºç›¤ã¨ãªã‚‹ã‚‚ã®ã‚’ç§»å‹•
            0 if m.destination.parts[-2] in ['utils', 'models', 'constants'] else 1,
            # æ¬¡ã«ãƒªãƒã‚¸ãƒˆãƒªã‚„ã‚µãƒ¼ãƒ“ã‚¹
            0 if m.destination.parts[-2] in ['repositories', 'services'] else 1,
            # æœ€å¾Œã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ãªã©ä¸Šä½å±¤
            str(m.source)
        ))
        
    def _create_import_update_plan(self) -> None:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°è¨ˆç”»ã‚’ä½œæˆ"""
        # ç§»å‹•ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        move_mapping = {}
        for move in self.file_moves:
            old_module = self._path_to_module(move.source)
            new_module = self._path_to_module(move.destination)
            move_mapping[old_module] = new_module
            
        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
        for py_file in self.src_dir.rglob("*.py"):
            if "__pycache__" in str(py_file):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    
                for i, line in enumerate(lines):
                    for old_module, new_module in move_mapping.items():
                        if f"from {old_module}" in line or f"import {old_module}" in line:
                            new_line = line.replace(old_module, new_module)
                            
                            update = ImportUpdate(
                                file_path=py_file,
                                old_import=line.strip(),
                                new_import=new_line.strip(),
                                line_number=i + 1
                            )
                            self.import_updates.append(update)
                            
            except Exception as e:
                print(f"âš ï¸  {py_file}ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                
    def _path_to_module(self, path: Path) -> str:
        """ãƒ‘ã‚¹ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã«å¤‰æ›"""
        try:
            relative = path.relative_to(self.src_dir)
            parts = list(relative.parts)
            if parts[-1].endswith('.py'):
                parts[-1] = parts[-1][:-3]
            return '.'.join(parts)
        except ValueError:
            return str(path)
            
    def _execute_organization(self) -> None:
        """å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•"""
        print("\nğŸš€ ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã‚’å®Ÿè¡Œä¸­...")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.src_dir.parent / f".file_org_backup_{timestamp}"
        backup_dir.mkdir(exist_ok=True)
        
        # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’åˆæœŸåŒ–
        self.rollback_info = RollbackInfo(
            timestamp=timestamp,
            moves=[],
            import_updates=[],
            backup_dir=backup_dir
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
        for move in self.file_moves:
            try:
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                backup_path = backup_dir / move.source.relative_to(self.src_dir)
                backup_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(move.source, backup_path)
                
                # ç§»å‹•å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                move.destination.parent.mkdir(parents=True, exist_ok=True)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
                shutil.move(str(move.source), str(move.destination))
                self.rollback_info.moves.append(move)
                
                print(f"âœ… ç§»å‹•: {move.source} â†’ {move.destination}")
                
                # å¿…è¦ã«å¿œã˜ã¦__init__.pyã‚’ä½œæˆ
                self._ensure_init_files(move.destination.parent)
                
            except Exception as e:
                print(f"âŒ ç§»å‹•å¤±æ•—: {move.source} - {e}")
                
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ›´æ–°
        self._update_imports()
        
        # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’ä¿å­˜
        self._save_rollback_info()
        
        # ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
        self._cleanup_empty_dirs()
        
    def _ensure_init_files(self, directory: Path) -> None:
        """__init__.pyãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºä¿"""
        current = directory
        while current != self.src_dir and current != current.parent:
            init_file = current / "__init__.py"
            if not init_file.exists():
                init_file.touch()
                print(f"ğŸ“„ ä½œæˆ: {init_file}")
            current = current.parent
            
    def _update_imports(self) -> None:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’æ›´æ–°"""
        files_to_update = defaultdict(list)
        
        for update in self.import_updates:
            files_to_update[update.file_path].append(update)
            
        for file_path, updates in files_to_update.items():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                if self.rollback_info:
                    backup_path = self.rollback_info.backup_dir / file_path.relative_to(self.src_dir)
                    backup_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(file_path, backup_path)
                    
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ›´æ–°
                for update in updates:
                    content = content.replace(update.old_import, update.new_import)
                    
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
                print(f"ğŸ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°: {file_path} ({len(updates)}ç®‡æ‰€)")
                
                if self.rollback_info:
                    self.rollback_info.import_updates.extend(updates)
                    
            except Exception as e:
                print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°å¤±æ•—: {file_path} - {e}")
                
    def _cleanup_empty_dirs(self) -> None:
        """ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤"""
        for root, dirs, files in os.walk(self.src_dir, topdown=False):
            if not files and not dirs and root != str(self.src_dir):
                try:
                    Path(root).rmdir()
                    print(f"ğŸ—‘ï¸  ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤: {root}")
                except Exception:
                    pass
                    
    def _save_rollback_info(self) -> None:
        """ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’ä¿å­˜"""
        if self.rollback_info:
            rollback_file = self.src_dir.parent / f".rollback_{self.rollback_info.timestamp}.json"
            
            data = {
                'timestamp': self.rollback_info.timestamp,
                'backup_dir': str(self.rollback_info.backup_dir),
                'moves': [
                    {
                        'source': str(m.source),
                        'destination': str(m.destination),
                        'reason': m.reason
                    }
                    for m in self.rollback_info.moves
                ],
                'import_updates': [
                    {
                        'file_path': str(u.file_path),
                        'old_import': u.old_import,
                        'new_import': u.new_import,
                        'line_number': u.line_number
                    }
                    for u in self.rollback_info.import_updates
                ]
            }
            
            with open(rollback_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
            print(f"\nğŸ’¾ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’ä¿å­˜: {rollback_file}")
            
    def _show_simulation(self) -> None:
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’è¡¨ç¤º"""
        print("\nğŸ“‹ å®Ÿè¡Œè¨ˆç”»ï¼ˆDry Runï¼‰:")
        
        if self.file_moves:
            print("\nğŸšš ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•:")
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            moves_by_category = defaultdict(list)
            for move in self.file_moves:
                category = move.destination.parts[-2] if len(move.destination.parts) > 1 else 'root'
                moves_by_category[category].append(move)
                
            for category, moves in sorted(moves_by_category.items()):
                print(f"\n  ğŸ“ {category}/")
                for move in moves:
                    print(f"    â”œâ”€ {move.source.name} â† {move.source.parent}")
                    print(f"    â”‚  ç†ç”±: {move.reason}")
                    
        if self.import_updates:
            print(f"\nğŸ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°: {len(self.import_updates)}ç®‡æ‰€")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            updates_by_file = defaultdict(int)
            for update in self.import_updates:
                updates_by_file[update.file_path] += 1
                
            for file_path, count in sorted(updates_by_file.items()):
                print(f"  - {file_path}: {count}ç®‡æ‰€")
                
    def rollback(self, rollback_file: Path) -> bool:
        """æ•´ç†ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        print(f"\nğŸ”„ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Ÿè¡Œ: {rollback_file}")
        
        try:
            with open(rollback_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            backup_dir = Path(data['backup_dir'])
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ƒã«æˆ»ã™
            for move_data in reversed(data['moves']):
                src = Path(move_data['destination'])
                dst = Path(move_data['source'])
                
                if src.exists():
                    dst.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(src), str(dst))
                    print(f"âœ… å¾©å…ƒ: {dst}")
                    
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¾©å…ƒ
            for root, dirs, files in os.walk(backup_dir):
                for file in files:
                    backup_file = Path(root) / file
                    relative = backup_file.relative_to(backup_dir)
                    original = self.src_dir / relative
                    
                    original.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(backup_file, original)
                    print(f"âœ… å¾©å…ƒ: {original}")
                    
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
            shutil.rmtree(backup_dir)
            
            print("\nâœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e}")
            return False


def main() -> CheckResult:
    project_root = Path(__file__).parent.parent.parent.parent
    src_dir = project_root / 'src'
    
    print(f"ğŸ” è«–ç†çš„ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†è§£æã‚’é–‹å§‹: {src_dir}")
    
    # Dry runãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ
    organizer = LogicalFileOrganizer(str(src_dir), dry_run=True)
    file_moves, import_updates = organizer.organize()
    
    failure_locations = []
    
    # ç§»å‹•ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’failure_locationsã«è¿½åŠ 
    for move in file_moves:
        failure_locations.append(FailureLocation(
            file_path=str(move.source),
            line_number=0
        ))
        
    if failure_locations:
        fix_policy = (
            f"{len(file_moves)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è«–ç†çš„ãªãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã«å†é…ç½®ã—ã¾ã™ã€‚\n"
            f"ãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰æ©Ÿèƒ½ãŒä¸€ç›®ã§ã‚ã‹ã‚‹æ§‹é€ ã«ãªã‚Šã¾ã™ã€‚\n"
            f"å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {len(import_updates)}ç®‡æ‰€"
        )
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ç§»å‹•æ•°ã‚’é›†è¨ˆ
        category_counts = defaultdict(int)
        for move in file_moves:
            category = move.destination.parts[-2] if len(move.destination.parts) > 1 else 'root'
            category_counts[category] += 1
            
        fix_example = "# æ•´ç†å¾Œã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ :\nsrc/\n"
        for category, count in sorted(category_counts.items()):
            fix_example += f"  {category}/  # {count}ãƒ•ã‚¡ã‚¤ãƒ«\n"
            
    else:
        fix_policy = "ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã¯æ—¢ã«è«–ç†çš„ã«æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚"
        fix_example = None
        
    return CheckResult(
        failure_locations=failure_locations,
        fix_policy=fix_policy,
        fix_example_code=fix_example
    )


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    result = main(None)
    print(f"\nCheckResult: {len(result.failure_locations)} files need reorganization")