import ast
import os
import sys
import json
import shutil
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, Any, Union
from dataclasses import dataclass, field
from collections import defaultdict
from datetime import datetime
import re

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))
from models.check_result import CheckResult, FailureLocation


@dataclass
class FileMove:
    source: Path
    destination: Path
    reason: str
    element_type: str  # 'function', 'class', 'module'
    element_name: str


@dataclass
class ImportUpdate:
    file_path: Path
    old_import: str
    new_import: str
    line_number: int


@dataclass
class RollbackInfo:
    timestamp: str
    moves: List[FileMove]
    import_updates: List[ImportUpdate]
    backup_dir: Path


class LogicalFileOrganizer:
    """è«–ç†çš„ãªæ§‹é€ ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ•´ç†ã™ã‚‹ãƒ„ãƒ¼ãƒ«"""
    
    # Clean Architectureæº–æ‹ ã®ã‚«ãƒ†ã‚´ãƒªã¨å¯¾å¿œã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€å
    CLEAN_ARCHITECTURE_CATEGORIES = {
        # Domain Layer - ãƒ”ãƒ¥ã‚¢ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒ“ã‚¹
        'domain': {
            'patterns': ['config_node', 'base_request', 'base_composite_request', 'workflow', 'step', 'dependency'],
            'keywords': ['entity', 'domain', 'value_object', 'aggregate', 'specification'],
            'interfaces': ['interface', 'protocol'],
            'description': 'Pure business logic entities and domain services'
        },
        
        # Application Layer - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒ“ã‚¹ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã€ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        'application': {
            'patterns': ['workflow_execution_svc', 'step_generation_svc', 'config_loader_svc', 'contest_mgmt', 'debug_svc'],
            'keywords': ['service', 'execution', 'orchestrat', 'usecase', 'application', 'coordinator'],
            'suffixes': ['_svc', '_service', '_manager', '_coordinator'],
            'description': 'Application services and use case orchestration'
        },
        
        # Infrastructure Layer - å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æºã€æ°¸ç¶šåŒ–ã€ãƒ‡ãƒã‚¤ã‚¹ãƒ‰ãƒ©ã‚¤ãƒ
        'infrastructure': {
            'patterns': ['docker_driver', 'file_driver', 'shell_driver', 'sqlite_mgmt', 'persistence_driver',
                        'local_file_driver', 'local_shell_driver', 'unified_driver', 'python_driver',
                        'mock_docker_driver', 'mock_file_driver', 'mock_python_driver', 'mock_shell_driver',
                        'docker_driver_with_tracking', 'fast_sqlite_mgmt'],
            'keywords': ['driver', 'repository', 'adapter', 'connector', 'persistence', 'database', 'external'],
            'suffixes': ['_driver', '_repository', '_adapter', '_connector', '_provider'],
            'description': 'External system integration and data persistence'
        },
        
        # Operations Layer - æ¨ªæ–­çš„é–¢å¿ƒäº‹ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€å‹å®šç¾©
        'operations': {
            'patterns': ['docker_request', 'file_request', 'shell_request', 'python_request', 'composite_request',
                        'docker_result', 'file_result', 'shell_result', 'workflow_result',
                        'docker_interface', 'execution_interface', 'output_manager_interface',
                        'composite_step_failure', 'error_converter', 'result_factory', 'request_factory'],
            'keywords': ['request', 'result', 'interface', 'factory', 'converter', 'exception', 'error'],
            'suffixes': ['_request', '_result', '_interface', '_factory', '_converter', '_exception'],
            'description': 'Cross-cutting concerns and interface definitions'
        },
        
        # Presentation Layer - CLIã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        'presentation': {
            'patterns': ['cli_app', 'main', 'context_formatter', 'context_validator', 'user_input_parser'],
            'keywords': ['cli', 'main', 'formatter', 'validator', 'parser', 'ui', 'presentation'],
            'suffixes': ['_formatter', '_validator', '_parser', '_cli'],
            'description': 'User interface and presentation logic'
        },
        
        # Utilities - ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€ãƒ˜ãƒ«ãƒ‘ãƒ¼ã€å…±é€šãƒ­ã‚¸ãƒƒã‚¯
        'utils': {
            'patterns': ['python_utils', 'path_operations', 'retry_decorator', 'time_adapter', 'sys_provider',
                        'regex_provider', 'mock_regex_provider', 'format_info'],
            'keywords': ['util', 'helper', 'common', 'shared', 'decorator', 'adapter', 'operations'],
            'suffixes': ['_utils', '_helper', '_decorator', '_adapter', '_operations', '_provider'],
            'description': 'Common utilities and helper functions'
        },
        
        # Logging - ãƒ­ã‚°é–¢é€£
        'logging': {
            'patterns': ['unified_logger', 'application_logger_adapter', 'workflow_logger_adapter', 'output_mgmt', 'mock_output_mgmt'],
            'keywords': ['logger', 'logging', 'log', 'output'],
            'suffixes': ['_logger', '_adapter', '_mgmt'],
            'description': 'Logging and output management'
        },
        
        # Configuration - è¨­å®šç®¡ç†ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ã¨ã¯åˆ†é›¢ï¼‰
        'configuration': {
            'patterns': ['configuration', 'di_config', 'build_infrastructure', 'environment_mgmt', 'system_config_loader', 'system_config_repository'],
            'keywords': ['config', 'configuration', 'settings', 'environment', 'setup'],
            'suffixes': ['_config', '_configuration', '_settings', '_loader'],
            'description': 'Configuration management and system setup'
        },
        
        # Data Access - ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹å±¤
        'data': {
            'patterns': ['docker_container_repository', 'docker_image_repository', 'operation_repository',
                        'session_repository', 'sqlite_state_repository', 'state_repository', 'base_repository'],
            'keywords': ['repository', 'dao', 'data', 'persistence', 'storage'],
            'suffixes': ['_repository', '_dao'],
            'description': 'Data access and repository patterns'
        }
    }
    
    def __init__(self, src_dir: str, dry_run: bool = True):
        self.src_dir = Path(src_dir)
        self.dry_run = dry_run
        self.file_moves: List[FileMove] = []
        self.import_updates: List[ImportUpdate] = []
        self.rollback_info: Optional[RollbackInfo] = None
        
    def organize(self) -> Tuple[List[FileMove], List[ImportUpdate]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è«–ç†çš„ã«æ•´ç†"""
        print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã‚’{'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³' if self.dry_run else 'å®Ÿè¡Œ'}ã—ã¾ã™: {self.src_dir}")
        
        # 1. ç¾åœ¨ã®æ§‹é€ ã‚’åˆ†æ
        self._analyze_current_structure()
        
        # 2. è«–ç†çš„ãªç§»å‹•è¨ˆç”»ã‚’ä½œæˆ
        self._create_move_plan()
        
        # 3. ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°è¨ˆç”»ã‚’ä½œæˆ
        self._create_import_update_plan()
        
        # 4. å®Ÿè¡Œã¾ãŸã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        if not self.dry_run:
            self._execute_organization()
        else:
            self._show_simulation()
            
        return self.file_moves, self.import_updates
        
    def _analyze_current_structure(self) -> None:
        """ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’åˆ†æ"""
        print("\nğŸ“Š ç¾åœ¨ã®æ§‹é€ ã‚’åˆ†æä¸­...")
        
        for py_file in self.src_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "_test.py" in str(py_file):
                continue
                
            logical_category = self._determine_logical_category(py_file)
            if logical_category:
                ideal_path = self._get_ideal_path(py_file, logical_category)
                
                if ideal_path != py_file:
                    move = FileMove(
                        source=py_file,
                        destination=ideal_path,
                        reason=f"{logical_category}ã‚«ãƒ†ã‚´ãƒªã«å±ã™ã‚‹ãŸã‚",
                        element_type=self._get_element_type(py_file),
                        element_name=py_file.stem
                    )
                    self.file_moves.append(move)
                    
    def _determine_logical_category(self, file_path: Path) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è«–ç†çš„ã‚«ãƒ†ã‚´ãƒªã‚’Clean Architectureæº–æ‹ ã§åˆ¤å®š"""
        file_name = file_path.stem.lower()
        parent_dir = file_path.parent.name.lower()
        
        # 1. ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹åˆ¤å®šï¼ˆæœ€å„ªå…ˆï¼‰
        for category, config in self.CLEAN_ARCHITECTURE_CATEGORIES.items():
            if 'patterns' in config:
                for pattern in config['patterns']:
                    if pattern in file_name or pattern in parent_dir:
                        return category
        
        # 2. ãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹åˆ¤å®š
        for category, config in self.CLEAN_ARCHITECTURE_CATEGORIES.items():
            if 'suffixes' in config:
                for suffix in config['suffixes']:
                    if file_name.endswith(suffix):
                        return category
        
        # 3. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹åˆ¤å®š
        for category, config in self.CLEAN_ARCHITECTURE_CATEGORIES.items():
            if 'keywords' in config:
                for keyword in config['keywords']:
                    if keyword in file_name:
                        return category
        
        # 4. ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼ˆã‚¯ãƒ©ã‚¹åã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰ã«ã‚ˆã‚‹åˆ¤å®š
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‹ã‚‰ä¾å­˜é–¢ä¿‚ã‚’åˆ†æ
            category_from_imports = self._analyze_imports_for_category(content)
            if category_from_imports:
                return category_from_imports
                
            # ã‚¯ãƒ©ã‚¹åã‹ã‚‰åˆ¤å®š
            tree = ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_name = node.name.lower()
                    for category, config in self.CLEAN_ARCHITECTURE_CATEGORIES.items():
                        if 'keywords' in config:
                            for keyword in config['keywords']:
                                if keyword in class_name:
                                    return category
                                    
        except Exception:
            pass
            
        return None
    
    def _analyze_imports_for_category(self, content: str) -> Optional[str]:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‹ã‚‰é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªã‚’æ¨å®šï¼ˆä¾å­˜é–¢ä¿‚åˆ†æå¼·åŒ–ç‰ˆï¼‰"""
        lines = content.split('\n')
        import_score = defaultdict(int)
        
        # å„ã‚«ãƒ†ã‚´ãƒªã®ç‰¹å¾´çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã‚¹ã‚³ã‚¢
        category_patterns = {
            'infrastructure': {
                'patterns': ['docker', 'container', 'image', 'shell', 'subprocess', 'pathlib', 'shutil', 'os.path'],
                'score': 3
            },
            'data': {
                'patterns': ['sqlite', 'database', 'db', 'repository', 'persistence', 'storage'],
                'score': 3
            },
            'logging': {
                'patterns': ['logging', 'logger', 'log', 'output', 'debug'],
                'score': 2
            },
            'presentation': {
                'patterns': ['argparse', 'click', 'cli', 'command', 'sys.argv', 'main'],
                'score': 3
            },
            'application': {
                'patterns': ['workflow', 'execution', 'service', 'orchestrat', 'coordinator'],
                'score': 2
            },
            'domain': {
                'patterns': ['entity', 'value', 'specification', 'aggregate', 'domain'],
                'score': 2
            },
            'operations': {
                'patterns': ['request', 'result', 'interface', 'protocol', 'factory', 'abc'],
                'score': 2
            },
            'utils': {
                'patterns': ['util', 'helper', 'common', 'decorator', 'typing', 'datetime'],
                'score': 1
            }
        }
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’è§£æã—ã¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        for line in lines:
            line = line.strip()
            if line.startswith(('import ', 'from ')):
                line_lower = line.lower()
                
                # å„ã‚«ãƒ†ã‚´ãƒªã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                for category, config in category_patterns.items():
                    for pattern in config['patterns']:
                        if pattern in line_lower:
                            import_score[category] += config['score']
                
                # ç‰¹åˆ¥ãªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                if 'src.infrastructure' in line:
                    import_score['application'] += 2  # infrastructureã‚’ä½¿ã†â†’applicationå±¤
                elif 'src.operations' in line:
                    import_score['application'] += 1  # operationsã‚’ä½¿ã†â†’applicationå±¤
                elif 'abc.ABC' in line or 'Protocol' in line:
                    import_score['operations'] += 2  # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©
                elif 'from typing import' in line:
                    import_score['operations'] += 1  # å‹å®šç¾©
        
        # æœ€ã‚‚ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã‚«ãƒ†ã‚´ãƒªã‚’è¿”ã™
        if import_score:
            best_category = max(import_score.items(), key=lambda x: x[1])
            if best_category[1] >= 2:  # é–¾å€¤ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ãŒã‚ã‚‹å ´åˆã®ã¿
                return best_category[0]
        
        return None
    
    def _analyze_dependency_relationships(self, file_path: Path, content: str) -> dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾å­˜é–¢ä¿‚ã‚’åˆ†æã—ã¦ã‚ˆã‚Šè©³ç´°ãªåˆ†é¡æƒ…å ±ã‚’å–å¾—"""
        dependencies = {
            'imports_infrastructure': False,
            'imports_domain': False,
            'imports_application': False,
            'imports_operations': False,
            'defines_interfaces': False,
            'contains_business_logic': False,
            'contains_external_calls': False
        }
        
        lines = content.split('\n')
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆåˆ†æ
        for line in lines:
            line = line.strip()
            if line.startswith(('import ', 'from ')):
                if 'src.infrastructure' in line:
                    dependencies['imports_infrastructure'] = True
                elif 'src.domain' in line or 'src.core' in line:
                    dependencies['imports_domain'] = True
                elif 'src.application' in line:
                    dependencies['imports_application'] = True
                elif 'src.operations' in line:
                    dependencies['imports_operations'] = True
        
        # ã‚³ãƒ¼ãƒ‰å†…å®¹åˆ†æ
        try:
            tree = ast.parse(content)
            for node in ast.walk(tree):
                # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©ãƒã‚§ãƒƒã‚¯
                if isinstance(node, ast.ClassDef):
                    for base in node.bases:
                        if isinstance(base, ast.Name) and base.id in ['ABC', 'Protocol']:
                            dependencies['defines_interfaces'] = True
                        elif isinstance(base, ast.Attribute) and base.attr in ['ABC', 'Protocol']:
                            dependencies['defines_interfaces'] = True
                
                # å¤–éƒ¨å‘¼ã³å‡ºã—ãƒã‚§ãƒƒã‚¯
                if isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Attribute):
                        # subprocess, docker, shutilç­‰ã®å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ å‘¼ã³å‡ºã—
                        if hasattr(node.func, 'value') and isinstance(node.func.value, ast.Name):
                            if node.func.value.id in ['subprocess', 'docker', 'shutil', 'os']:
                                dependencies['contains_external_calls'] = True
        
        except Exception:
            pass
        
        return dependencies
        
    def _get_ideal_path(self, current_path: Path, category: str) -> Path:
        """Clean Architectureæº–æ‹ ã®ç†æƒ³çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        # Clean Architectureå±¤åˆ¥ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        category_dir = self.src_dir / category
        
        # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®šï¼ˆä¾‹: docker_driver.py â†’ infrastructure/drivers/docker/ï¼‰
        file_stem = current_path.stem
        
        # Clean Architectureå›ºæœ‰ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ†é¡
        if category == 'infrastructure':
            if 'driver' in file_stem:
                driver_type = self._extract_driver_type(file_stem)
                return category_dir / 'drivers' / driver_type / current_path.name
            elif 'repository' in file_stem:
                return category_dir / 'repositories' / current_path.name
            elif 'adapter' in file_stem:
                return category_dir / 'adapters' / current_path.name
            else:
                return category_dir / current_path.name
                
        elif category == 'domain':
            if 'entity' in file_stem or 'model' in file_stem:
                return category_dir / 'entities' / current_path.name
            elif 'service' in file_stem:
                return category_dir / 'services' / current_path.name
            elif 'value' in file_stem:
                return category_dir / 'values' / current_path.name
            else:
                return category_dir / current_path.name
                
        elif category == 'application':
            if 'service' in file_stem or 'svc' in file_stem:
                return category_dir / 'services' / current_path.name
            elif 'usecase' in file_stem:
                return category_dir / 'usecases' / current_path.name
            else:
                return category_dir / current_path.name
                
        elif category == 'operations':
            if 'request' in file_stem:
                return category_dir / 'requests' / current_path.name
            elif 'result' in file_stem:
                return category_dir / 'results' / current_path.name
            elif 'interface' in file_stem:
                return category_dir / 'interfaces' / current_path.name
            elif 'factory' in file_stem:
                return category_dir / 'factories' / current_path.name
            else:
                return category_dir / current_path.name
                
        elif category == 'data':
            entity_name = self._extract_entity_name(file_stem)
            if entity_name:
                return category_dir / entity_name / current_path.name
            else:
                return category_dir / current_path.name
                
        # ãã®ä»–ã®ã‚«ãƒ†ã‚´ãƒªã¯ãƒ•ãƒ©ãƒƒãƒˆæ§‹é€ 
        return category_dir / current_path.name
    
    def _extract_driver_type(self, file_stem: str) -> str:
        """ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡ºï¼ˆä¾‹: docker_driver â†’ dockerï¼‰"""
        if 'docker' in file_stem:
            return 'docker'
        elif 'file' in file_stem:
            return 'file'
        elif 'shell' in file_stem:
            return 'shell'
        elif 'python' in file_stem:
            return 'python'
        else:
            return 'generic'
    
    def _extract_entity_name(self, file_stem: str) -> str:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã‚’æŠ½å‡ºï¼ˆä¾‹: user_repository â†’ userï¼‰"""
        # ã‚ˆãã‚ã‚‹ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã‚’æŠ½å‡º
        suffixes_to_remove = ['_repository', '_service', '_controller', '_model', '_entity']
        entity_name = file_stem
        
        for suffix in suffixes_to_remove:
            if entity_name.endswith(suffix):
                entity_name = entity_name[:-len(suffix)]
                break
                
        return entity_name if entity_name != file_stem else ""
        
    def _get_element_type(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ç´ ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            tree = ast.parse(content)
            
            has_classes = any(isinstance(node, ast.ClassDef) for node in ast.walk(tree))
            has_functions = any(isinstance(node, ast.FunctionDef) for node in ast.walk(tree))
            
            if has_classes:
                return 'class'
            elif has_functions:
                return 'function'
            else:
                return 'module'
                
        except Exception:
            return 'module'
            
    def _create_move_plan(self) -> None:
        """Clean Architectureä¾å­˜é–¢ä¿‚ã‚’è€ƒæ…®ã—ã¦ç§»å‹•è¨ˆç”»ã‚’æœ€é©åŒ–"""
        
        # Clean Architectureå±¤ã®ç§»å‹•å„ªå…ˆåº¦
        # ä¾å­˜é–¢ä¿‚ã®å°‘ãªã„å±¤ã‹ã‚‰ç§»å‹•ï¼ˆDomain â†’ Application â†’ Infrastructure â†’ Presentationï¼‰
        layer_priority = {
            'domain': 0,      # æœ€å„ªå…ˆï¼šãƒ”ãƒ¥ã‚¢ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã€ä¾å­˜é–¢ä¿‚ãªã—
            'utils': 1,       # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼šå¤šãã®å±¤ã‹ã‚‰ä¾å­˜ã•ã‚Œã‚‹
            'operations': 2,  # æ¨ªæ–­çš„é–¢å¿ƒäº‹ï¼šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©
            'data': 3,        # ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ï¼šãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¾å­˜
            'application': 4, # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ï¼šãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¾å­˜
            'logging': 5,     # ãƒ­ã‚°ï¼šå¤šãã®å±¤ã‹ã‚‰ä½¿ç”¨ã•ã‚Œã‚‹
            'configuration': 6, # è¨­å®šï¼šã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‹ã‚‰ä½¿ç”¨
            'infrastructure': 7, # ã‚¤ãƒ³ãƒ•ãƒ©å±¤ï¼šå¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æº
            'presentation': 8  # ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å±¤ï¼šæœ€ä¸Šä½ã€ä»–å…¨ã¦ã«ä¾å­˜
        }
        
        def get_move_priority(move: FileMove) -> tuple:
            # ç§»å‹•å…ˆã®ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®š
            try:
                # ãƒ‘ã‚¹ã‹ã‚‰å±¤ã‚’æŠ½å‡ºï¼ˆä¾‹: src/domain/entities/config_node.py â†’ domainï¼‰
                path_parts = move.destination.parts
                src_index = None
                for i, part in enumerate(path_parts):
                    if part == 'src':
                        src_index = i
                        break
                
                if src_index is not None and src_index + 1 < len(path_parts):
                    layer = path_parts[src_index + 1]
                    priority = layer_priority.get(layer, 99)
                else:
                    priority = 99
                    
            except Exception:
                priority = 99
            
            return (priority, str(move.source))
        
        # ä¾å­˜é–¢ä¿‚ã‚’è€ƒæ…®ã—ã¦ã‚½ãƒ¼ãƒˆ
        self.file_moves.sort(key=get_move_priority)
        
        # ç§»å‹•è¨ˆç”»ã®è©³ç´°ãƒ­ã‚°
        print(f"ğŸ“‹ ç§»å‹•è¨ˆç”»ã‚’ä¾å­˜é–¢ä¿‚é †ã«æ•´ç†ã—ã¾ã—ãŸ:")
        for i, move in enumerate(self.file_moves[:5]):  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
            layer = move.destination.parts[-2] if len(move.destination.parts) > 1 else 'unknown'
            print(f"  {i+1}. {layer}: {move.source.name}")
        if len(self.file_moves) > 5:
            print(f"  ... ä»– {len(self.file_moves) - 5} ä»¶")
        
    def _create_import_update_plan(self) -> None:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°è¨ˆç”»ã‚’ä½œæˆ"""
        # ç§»å‹•ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        move_mapping = {}
        for move in self.file_moves:
            old_module = self._path_to_module(move.source)
            new_module = self._path_to_module(move.destination)
            move_mapping[old_module] = new_module
            
        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
        for py_file in self.src_dir.rglob("*.py"):
            if "__pycache__" in str(py_file):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    
                # ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã§æ–‡å­—åˆ—ç½®æ›ï¼ˆæ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«å†…ã‚‚å«ã‚€ï¼‰
                content = ''.join(lines)
                updated_content = content
                has_updates = False
                
                for old_module, new_module in move_mapping.items():
                    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®ç½®æ›ãƒ‘ã‚¿ãƒ¼ãƒ³
                    patterns = [
                        f"from {old_module} import",
                        f"from {old_module}.",  # from src.configuration.config_manager import
                        f"import {old_module}",
                        f"'{old_module}'",      # æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«å†…ã‚‚å¯¾è±¡
                        f'"{old_module}"',      # ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆæ–‡å­—åˆ—ã‚‚å¯¾è±¡
                    ]
                    
                    for pattern in patterns:
                        if pattern in updated_content:
                            replacement = pattern.replace(old_module, new_module)
                            updated_content = updated_content.replace(pattern, replacement)
                            has_updates = True
                
                if has_updates:
                    update = ImportUpdate(
                        file_path=py_file,
                        old_import=content,
                        new_import=updated_content,
                        line_number=0
                    )
                    self.import_updates.append(update)
                            
            except Exception as e:
                print(f"âš ï¸  {py_file}ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                
    def _path_to_module(self, path: Path) -> str:
        """ãƒ‘ã‚¹ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã«å¤‰æ›"""
        try:
            relative = path.relative_to(self.src_dir)
            parts = list(relative.parts)
            if parts[-1].endswith('.py'):
                parts[-1] = parts[-1][:-3]
            return '.'.join(parts)
        except ValueError:
            return str(path)
            
    def _execute_organization(self) -> None:
        """å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•"""
        print("\nğŸš€ ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã‚’å®Ÿè¡Œä¸­...")
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ç„¡åŠ¹åŒ–ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_dir = Path("src_check/auto_correct_log")
        log_dir.mkdir(exist_ok=True)
        
        # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’åˆæœŸåŒ–ï¼ˆãƒ­ã‚°ã®ã¿ï¼‰
        self.rollback_info = RollbackInfo(
            timestamp=timestamp,
            moves=[],
            import_updates=[],
            backup_dir=log_dir  # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ã—ã¦ä½¿ç”¨
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
        for move in self.file_moves:
            try:
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ç„¡åŠ¹åŒ–ï¼ˆGitã§ç®¡ç†ï¼‰
                
                # ç§»å‹•å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                move.destination.parent.mkdir(parents=True, exist_ok=True)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
                shutil.move(str(move.source), str(move.destination))
                self.rollback_info.moves.append(move)
                
                print(f"âœ… ç§»å‹•: {move.source} â†’ {move.destination}")
                
                # å¿…è¦ã«å¿œã˜ã¦__init__.pyã‚’ä½œæˆ
                self._ensure_init_files(move.destination.parent)
                
            except Exception as e:
                print(f"âŒ ç§»å‹•å¤±æ•—: {move.source} - {e}")
                
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ›´æ–°
        self._update_imports()
        
        # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’ä¿å­˜
        self._save_rollback_info()
        
        # ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
        self._cleanup_empty_dirs()
        
    def _ensure_init_files(self, directory: Path) -> None:
        """__init__.pyãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºä¿"""
        current = directory
        while current != self.src_dir and current != current.parent:
            init_file = current / "__init__.py"
            if not init_file.exists():
                init_file.touch()
                print(f"ğŸ“„ ä½œæˆ: {init_file}")
            current = current.parent
            
    def _update_imports(self) -> None:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’æ›´æ–°"""
        files_to_update = defaultdict(list)
        
        for update in self.import_updates:
            files_to_update[update.file_path].append(update)
            
        for file_path, updates in files_to_update.items():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ç„¡åŠ¹åŒ–ï¼ˆGitã§ç®¡ç†ï¼‰
                    
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ›´æ–°
                for update in updates:
                    if update.line_number == 0:  # ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã®ç½®æ›
                        content = update.new_import
                    else:  # è¡Œå˜ä½ã®ç½®æ›
                        content = content.replace(update.old_import, update.new_import)
                    
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
                print(f"ğŸ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°: {file_path} ({len(updates)}ç®‡æ‰€)")
                
                if self.rollback_info:
                    self.rollback_info.import_updates.extend(updates)
                    
            except Exception as e:
                print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°å¤±æ•—: {file_path} - {e}")
                
    def _cleanup_empty_dirs(self) -> None:
        """ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤"""
        for root, dirs, files in os.walk(self.src_dir, topdown=False):
            if not files and not dirs and root != str(self.src_dir):
                try:
                    Path(root).rmdir()
                    print(f"ğŸ—‘ï¸  ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤: {root}")
                except Exception:
                    pass
                    
    def _save_rollback_info(self) -> None:
        """ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’ä¿å­˜"""
        if self.rollback_info:
            rollback_file = self.rollback_info.backup_dir / f"operation_log_{self.rollback_info.timestamp}.json"
            
            data = {
                'timestamp': self.rollback_info.timestamp,
                'log_dir': str(self.rollback_info.backup_dir),
                'note': 'ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚å¤‰æ›´ã¯Gitã§ç®¡ç†ã—ã¦ãã ã•ã„ã€‚',
                'moves': [
                    {
                        'source': str(m.source),
                        'destination': str(m.destination),
                        'reason': m.reason
                    }
                    for m in self.rollback_info.moves
                ],
                'import_updates': [
                    {
                        'file_path': str(u.file_path),
                        'old_import': u.old_import,
                        'new_import': u.new_import,
                        'line_number': u.line_number
                    }
                    for u in self.rollback_info.import_updates
                ]
            }
            
            with open(rollback_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
            print(f"\nğŸ’¾ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’ä¿å­˜: {rollback_file}")
            
    def _show_simulation(self) -> None:
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’è¡¨ç¤º"""
        print("\nğŸ“‹ å®Ÿè¡Œè¨ˆç”»ï¼ˆDry Runï¼‰:")
        
        if self.file_moves:
            print("\nğŸšš ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•:")
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            moves_by_category = defaultdict(list)
            for move in self.file_moves:
                category = move.destination.parts[-2] if len(move.destination.parts) > 1 else 'root'
                moves_by_category[category].append(move)
                
            for category, moves in sorted(moves_by_category.items()):
                print(f"\n  ğŸ“ {category}/")
                for move in moves:
                    print(f"    â”œâ”€ {move.source.name} â† {move.source.parent}")
                    print(f"    â”‚  ç†ç”±: {move.reason}")
                    
        if self.import_updates:
            print(f"\nğŸ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ›´æ–°: {len(self.import_updates)}ç®‡æ‰€")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            updates_by_file = defaultdict(int)
            for update in self.import_updates:
                updates_by_file[update.file_path] += 1
                
            for file_path, count in sorted(updates_by_file.items()):
                print(f"  - {file_path}: {count}ç®‡æ‰€")
                
    def rollback(self, rollback_file: Path) -> bool:
        """æ•´ç†ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆç„¡åŠ¹åŒ–æ¸ˆã¿ï¼‰"""
        print(f"\nâŒ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        print(f"    å¤‰æ›´ã¯Gitã§ç®¡ç†ã—ã¦ãã ã•ã„ã€‚")
        print(f"    git reset --hard HEAD ã¾ãŸã¯ git checkout ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¾©å…ƒã—ã¦ãã ã•ã„ã€‚")
        print(f"    ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {rollback_file}")
        return False


def main() -> CheckResult:
    project_root = Path(__file__).parent.parent.parent.parent
    src_dir = project_root / 'src'
    
    print(f"ğŸ” è«–ç†çš„ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†è§£æã‚’é–‹å§‹: {src_dir}")
    
    # DRY_RUNãƒ¢ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
    import os
    dry_run = bool(os.environ.get('SRC_CHECK_DRY_RUN', False))
    organizer = LogicalFileOrganizer(str(src_dir), dry_run=dry_run)
    file_moves, import_updates = organizer.organize()
    
    failure_locations = []
    
    # ç§»å‹•ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’failure_locationsã«è¿½åŠ 
    for move in file_moves:
        failure_locations.append(FailureLocation(
            file_path=str(move.source),
            line_number=0
        ))
        
    if failure_locations:
        fix_policy = (
            f"{len(file_moves)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è«–ç†çš„ãªãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã«å†é…ç½®ã—ã¾ã™ã€‚\n"
            f"ãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰æ©Ÿèƒ½ãŒä¸€ç›®ã§ã‚ã‹ã‚‹æ§‹é€ ã«ãªã‚Šã¾ã™ã€‚\n"
            f"å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {len(import_updates)}ç®‡æ‰€"
        )
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ç§»å‹•æ•°ã‚’é›†è¨ˆ
        category_counts = defaultdict(int)
        for move in file_moves:
            category = move.destination.parts[-2] if len(move.destination.parts) > 1 else 'root'
            category_counts[category] += 1
            
        fix_example = "# æ•´ç†å¾Œã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ :\nsrc/\n"
        for category, count in sorted(category_counts.items()):
            fix_example += f"  {category}/  # {count}ãƒ•ã‚¡ã‚¤ãƒ«\n"
            
    else:
        fix_policy = "ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã¯æ—¢ã«è«–ç†çš„ã«æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚"
        fix_example = None
        
    return CheckResult(
        failure_locations=failure_locations,
        fix_policy=fix_policy,
        fix_example_code=fix_example
    )


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    result = main()
    print(f"\nCheckResult: {len(result.failure_locations)} files need reorganization")