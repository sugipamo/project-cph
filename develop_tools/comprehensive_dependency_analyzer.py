#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„ãªä¾å­˜é–¢ä¿‚å•é¡Œåˆ†æ - å…·ä½“çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç‰¹å®š
"""

import ast
import json
from collections import defaultdict
from pathlib import Path


class ComprehensiveDependencyAnalyzer:
    def __init__(self, src_path: str):
        self.src_path = Path(src_path)
        self.problems = {
            'circular_imports': [],
            'layer_violations': [],
            'tight_coupling': [],
            'shared_utils_overuse': [],
            'env_layer_issues': []
        }

    def analyze_file_imports(self, file_path: Path) -> dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è©³ç´°ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆæƒ…å ±ã‚’æŠ½å‡º"""
        try:
            with open(file_path, encoding='utf-8') as f:
                lines = f.readlines()
                content = ''.join(lines)

            tree = ast.parse(content)
            imports = []

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append({
                            'type': 'import',
                            'module': alias.name,
                            'alias': alias.asname,
                            'line': node.lineno,
                            'line_text': lines[node.lineno - 1].strip() if node.lineno <= len(lines) else ""
                        })
                elif isinstance(node, ast.ImportFrom) and node.module:
                    imports.append({
                        'type': 'from_import',
                        'module': node.module,
                        'names': [alias.name for alias in node.names],
                        'line': node.lineno,
                        'line_text': lines[node.lineno - 1].strip() if node.lineno <= len(lines) else "",
                        'level': node.level
                    })

            return {
                'file_path': str(file_path),
                'imports': imports,
                'total_lines': len(lines)
            }
        except Exception as e:
            return {
                'file_path': str(file_path),
                'imports': [],
                'error': str(e),
                'total_lines': 0
            }

    def determine_layer(self, module_path: str) -> str:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ç‰¹å®š"""
        if module_path.startswith('src.domain'):
            return 'domain'
        if module_path.startswith('src.infrastructure'):
            return 'infrastructure'
        if module_path.startswith('src.application'):
            return 'application'
        if module_path.startswith('src.context'):
            return 'context'
        if module_path.startswith('src.shared'):
            return 'shared'
        if module_path.startswith('src.env_core'):
            return 'env_core'
        if module_path.startswith('src.env_integration'):
            return 'env_integration'
        if module_path.startswith('src.utils'):
            return 'utils'
        if module_path.startswith('src.workflow'):
            return 'workflow'
        if module_path.startswith('src.pure_functions'):
            return 'pure_functions'
        return 'unknown'

    def get_module_path(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        relative_path = file_path.relative_to(self.src_path)
        if relative_path.name == "__init__.py":
            if str(relative_path.parent) == ".":
                return "src"
            return "src." + str(relative_path.parent).replace("/", ".")
        module_path = str(relative_path.with_suffix("")).replace("/", ".")
        return "src." + module_path

    def analyze_layer_violations(self) -> list[dict]:
        """å…·ä½“çš„ãªãƒ¬ã‚¤ãƒ¤ãƒ¼é•åã‚’ç‰¹å®š"""
        violations = []

        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ«ãƒ¼ãƒ«å®šç¾©
        forbidden_dependencies = [
            # domainãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ä»–ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ä¾å­˜ã—ã¦ã¯ã„ã‘ãªã„
            ('domain', ['infrastructure', 'application', 'context'], 'Domain layer should not depend on infrastructure, application, or context layers'),
            # infrastructureãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯applicationãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ä¾å­˜ã—ã¦ã¯ã„ã‘ãªã„
            ('infrastructure', ['application'], 'Infrastructure layer should not depend on application layer'),
            # sharedãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ç‰¹å®šã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ä¾å­˜ã—ã¦ã¯ã„ã‘ãªã„
            ('shared', ['application', 'context'], 'Shared layer should not depend on application or context layers'),
            # env_coreã¯env_integrationã«ä¾å­˜ã—ã¦ã¯ã„ã‘ãªã„
            ('env_core', ['env_integration'], 'Core environment should not depend on integration layer')
        ]

        for py_file in self.src_path.rglob("*.py"):
            file_info = self.analyze_file_imports(py_file)
            module_path = self.get_module_path(py_file)
            source_layer = self.determine_layer(module_path)

            for import_info in file_info['imports']:
                import_module = import_info['module']
                if import_module.startswith('src.'):
                    target_layer = self.determine_layer(import_module)

                    # ãƒ«ãƒ¼ãƒ«é•åã‚’ãƒã‚§ãƒƒã‚¯
                    for source_pattern, forbidden_targets, rule_description in forbidden_dependencies:
                        if source_layer == source_pattern and target_layer in forbidden_targets:
                            violations.append({
                                'source_file': str(py_file),
                                'source_module': module_path,
                                'source_layer': source_layer,
                                'target_module': import_module,
                                'target_layer': target_layer,
                                'line_number': import_info['line'],
                                'import_statement': import_info['line_text'],
                                'rule_violation': rule_description,
                                'severity': self.get_violation_severity(source_layer, target_layer)
                            })

        return violations

    def get_violation_severity(self, source_layer: str, target_layer: str) -> str:
        """é•åã®é‡è¦åº¦ã‚’åˆ¤å®š"""
        high_severity_pairs = [
            ('domain', 'infrastructure'),
            ('domain', 'application'),
            ('env_core', 'env_integration')
        ]

        if (source_layer, target_layer) in high_severity_pairs:
            return 'high'
        if source_layer == 'shared' and target_layer in ['application', 'context']:
            return 'medium'
        return 'low'

    def analyze_shared_utils_overuse(self) -> list[dict]:
        """shared.utilsã®éåº¦ãªä½¿ç”¨ã‚’åˆ†æ"""
        shared_utils_usage = defaultdict(list)

        for py_file in self.src_path.rglob("*.py"):
            file_info = self.analyze_file_imports(py_file)
            module_path = self.get_module_path(py_file)

            for import_info in file_info['imports']:
                import_module = import_info['module']
                if import_module.startswith('src.shared.utils'):
                    shared_utils_usage[import_module].append({
                        'importing_file': str(py_file),
                        'importing_module': module_path,
                        'layer': self.determine_layer(module_path),
                        'line_number': import_info['line'],
                        'import_statement': import_info['line_text']
                    })

        # éåº¦ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ç‰¹å®š
        overused_utils = []
        for util_module, usages in shared_utils_usage.items():
            if len(usages) > 5:  # é–¾å€¤: 5å€‹ä»¥ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹
                overused_utils.append({
                    'utility_module': util_module,
                    'usage_count': len(usages),
                    'usages': usages
                })

        return overused_utils

    def analyze_complex_imports(self) -> list[dict]:
        """è¤‡é›‘ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆæ§‹é€ ã‚’åˆ†æ"""
        complex_files = []

        for py_file in self.src_path.rglob("*.py"):
            file_info = self.analyze_file_imports(py_file)
            internal_imports = [imp for imp in file_info['imports']
                              if imp['module'].startswith('src.')]

            if len(internal_imports) > 8:  # é–¾å€¤: 8å€‹ä»¥ä¸Šã®å†…éƒ¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                complex_files.append({
                    'file_path': str(py_file),
                    'module_path': self.get_module_path(py_file),
                    'internal_import_count': len(internal_imports),
                    'imports': internal_imports
                })

        return sorted(complex_files, key=lambda x: x['internal_import_count'], reverse=True)

    def analyze_env_dependencies(self) -> dict:
        """env_core/ã¨env_integration/é–“ã®ä¾å­˜é–¢ä¿‚å•é¡Œã‚’è©³ç´°åˆ†æ"""
        env_issues = {
            'core_to_integration_violations': [],
            'integration_modules_analysis': [],
            'core_modules_analysis': []
        }

        for py_file in self.src_path.rglob("*.py"):
            file_info = self.analyze_file_imports(py_file)
            module_path = self.get_module_path(py_file)

            if module_path.startswith('src.env_core'):
                # env_coreã‹ã‚‰env_integrationã¸ã®ä¾å­˜ã‚’ãƒã‚§ãƒƒã‚¯
                for import_info in file_info['imports']:
                    import_module = import_info['module']
                    if import_module.startswith('src.env_integration'):
                        env_issues['core_to_integration_violations'].append({
                            'source_file': str(py_file),
                            'source_module': module_path,
                            'target_module': import_module,
                            'line_number': import_info['line'],
                            'import_statement': import_info['line_text'],
                            'severity': 'high'
                        })

                env_issues['core_modules_analysis'].append({
                    'module': module_path,
                    'file_path': str(py_file),
                    'imports': [imp for imp in file_info['imports'] if imp['module'].startswith('src.')]
                })

            elif module_path.startswith('src.env_integration'):
                env_issues['integration_modules_analysis'].append({
                    'module': module_path,
                    'file_path': str(py_file),
                    'imports': [imp for imp in file_info['imports'] if imp['module'].startswith('src.')]
                })

        return env_issues

    def find_potential_circular_imports(self) -> list[dict]:
        """æ½œåœ¨çš„ãªå¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ç‰¹å®š"""
        # ã“ã®ã‚ˆã†ãªè©³ç´°ãªå¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œå‡ºã¯è¤‡é›‘ãªã®ã§ã€
        # ç°¡å˜ãªåŒæ–¹å‘ä¾å­˜ã‚’ãƒã‚§ãƒƒã‚¯
        module_dependencies = defaultdict(set)

        for py_file in self.src_path.rglob("*.py"):
            file_info = self.analyze_file_imports(py_file)
            module_path = self.get_module_path(py_file)

            for import_info in file_info['imports']:
                import_module = import_info['module']
                if import_module.startswith('src.'):
                    module_dependencies[module_path].add(import_module)

        # åŒæ–¹å‘ä¾å­˜ã‚’ãƒã‚§ãƒƒã‚¯
        bidirectional_deps = []
        checked_pairs = set()

        for mod_a, deps_a in module_dependencies.items():
            for mod_b in deps_a:
                if mod_b in module_dependencies and mod_a in module_dependencies[mod_b]:
                    pair = tuple(sorted([mod_a, mod_b]))
                    if pair not in checked_pairs:
                        checked_pairs.add(pair)
                        bidirectional_deps.append({
                            'module_a': mod_a,
                            'module_b': mod_b,
                            'type': 'bidirectional_dependency'
                        })

        return bidirectional_deps

    def generate_comprehensive_report(self) -> dict:
        """åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("ğŸ” åŒ…æ‹¬çš„ä¾å­˜é–¢ä¿‚åˆ†æã‚’å®Ÿè¡Œä¸­...")

        layer_violations = self.analyze_layer_violations()
        shared_utils_overuse = self.analyze_shared_utils_overuse()
        complex_imports = self.analyze_complex_imports()
        env_dependencies = self.analyze_env_dependencies()
        circular_imports = self.find_potential_circular_imports()

        return {
            'summary': {
                'layer_violations': len(layer_violations),
                'shared_utils_overuse': len(shared_utils_overuse),
                'complex_import_files': len(complex_imports),
                'env_core_violations': len(env_dependencies['core_to_integration_violations']),
                'potential_circular_imports': len(circular_imports)
            },
            'layer_violations': layer_violations,
            'shared_utils_overuse': shared_utils_overuse,
            'complex_imports': complex_imports,
            'env_dependencies': env_dependencies,
            'potential_circular_imports': circular_imports
        }

def main():
    analyzer = ComprehensiveDependencyAnalyzer("/home/cphelper/project-cph/src")
    report = analyzer.generate_comprehensive_report()

    print("\n" + "="*80)
    print("ğŸ“‹ åŒ…æ‹¬çš„ä¾å­˜é–¢ä¿‚å•é¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*80)

    print("\nğŸ“Š æ¦‚è¦:")
    print(f"  ğŸš¨ ãƒ¬ã‚¤ãƒ¤ãƒ¼é•å: {report['summary']['layer_violations']}")
    print(f"  ğŸ› ï¸  shared.utilséåº¦ä½¿ç”¨: {report['summary']['shared_utils_overuse']}")
    print(f"  ğŸ”— è¤‡é›‘ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {report['summary']['complex_import_files']}")
    print(f"  âš ï¸  env_coreé•å: {report['summary']['env_core_violations']}")
    print(f"  ğŸ”„ æ½œåœ¨çš„å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {report['summary']['potential_circular_imports']}")

    print("\nğŸš¨ ãƒ¬ã‚¤ãƒ¤ãƒ¼é•å (å…·ä½“çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡):")
    for i, violation in enumerate(report['layer_violations'][:10]):
        print(f"  {i+1}. ã€{violation['severity'].upper()}ã€‘")
        print(f"     ãƒ•ã‚¡ã‚¤ãƒ«: {violation['source_file']}")
        print(f"     è¡Œç•ªå·: {violation['line_number']}")
        print(f"     ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡: {violation['import_statement']}")
        print(f"     å•é¡Œ: {violation['source_layer']} â†’ {violation['target_layer']}")
        print(f"     ç†ç”±: {violation['rule_violation']}")
        print()

    print("\nğŸ› ï¸  shared.utilséåº¦ä½¿ç”¨:")
    for usage in report['shared_utils_overuse']:
        print(f"  ğŸ“¦ {usage['utility_module']} ({usage['usage_count']} å›ä½¿ç”¨)")
        for use in usage['usages'][:3]:  # æœ€åˆã®3ã¤ã‚’è¡¨ç¤º
            print(f"    - {use['importing_file']}:{use['line_number']}")
        if len(usage['usages']) > 3:
            print(f"    ... ä»– {len(usage['usages']) - 3} ä»¶")
        print()

    print("\nğŸ”— æœ€ã‚‚è¤‡é›‘ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆæ§‹é€ :")
    for i, complex_file in enumerate(report['complex_imports'][:5]):
        print(f"  {i+1}. {complex_file['file_path']}")
        print(f"     å†…éƒ¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ•°: {complex_file['internal_import_count']}")
        print(f"     ä¸»ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {[imp['module'] for imp in complex_file['imports'][:3]]}")
        print()

    if report['env_dependencies']['core_to_integration_violations']:
        print("\nâš ï¸  env_core â†’ env_integration é•å:")
        for violation in report['env_dependencies']['core_to_integration_violations']:
            print(f"  âŒ {violation['source_file']}:{violation['line_number']}")
            print(f"     {violation['import_statement']}")
            print()

    if report['potential_circular_imports']:
        print("\nğŸ”„ æ½œåœ¨çš„ãªå¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆ:")
        for circular in report['potential_circular_imports']:
            print(f"  â†”ï¸  {circular['module_a']} âŸ· {circular['module_b']}")

    # JSONãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
    with open("/home/cphelper/project-cph/comprehensive_dependency_analysis.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print("\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ comprehensive_dependency_analysis.json ã«ä¿å­˜ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
